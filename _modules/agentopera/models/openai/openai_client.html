

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>agentopera.models.openai.openai_client &mdash; AgentOpera API References 0.1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/css/theme.css?v=e59714d7" />

  
      <script src="../../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../../_static/documentation_options.js?v=01f34227"></script>
      <script src="../../../../_static/doctools.js?v=888ff710"></script>
      <script src="../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../../index.html" class="icon icon-home">
            AgentOpera API References
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Chatflow Module</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../chatflow/chatflow.html">chatflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../chatflow/chatflow.agents.html">chatflow.agents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../chatflow/chatflow.base.html">chatflow.base</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../chatflow/chatflow.conditions.html">chatflow.conditions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../chatflow/chatflow.media.html">chatflow.media</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../chatflow/chatflow.state.html">chatflow.state</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../chatflow/chatflow.team.html">chatflow.team</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../chatflow/chatflow.ui.html">chatflow.ui</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../chatflow/chatflow.utils.html">chatflow.utils</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Engine Module</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../engine/engine.html">engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../engine/engine.agent.html">engine.agent</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../engine/engine.function_call.html">engine.function_call</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../engine/engine.protocol.html">engine.protocol</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../engine/engine.runtime.html">engine.runtime</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../engine/engine.telemetry.html">engine.telemetry</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../engine/engine.types.html">engine.types</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Agents Module</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../agents/agents.html">agents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../agents/agents.openai.html">agents.openai</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../agents/agents.magentic_one.html">agents.magentic_one</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../agents/agents.magentic_one_team.html">agents.magentic_one_team</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../agents/agents.web_surfer.html">agents.web_surfer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../agents/agents.video_surfer.html">agents.video_surfer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../agents/agents.file_surfer.html">agents.file_surfer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../agents/agents.code_executor.html">agents.code_executor</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Router Module</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../router/router.html">router</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../router/router.workers.html">router.workers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../router/router.user.html">router.user</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../router/router.session.html">router.session</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Models Module</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../models/models.html">models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../models/models.openai.html">models.openai</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../models/models.anthropic.html">models.anthropic</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../models/models.azure.html">models.azure</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../models/models.ollama.html">models.ollama</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../models/models.replay.html">models.replay</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../models/models.cache.html">models.cache</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../models/models.utils.html">models.utils</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Memory Module</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../memory/memory.html">memory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../memory/memory.graphrag.html">memory.graphrag</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tools Module</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../tools/tools.html">tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tools/tools.http.html">tools.http</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tools/tools.code_execution.html">tools.code_execution</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">UI Module</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../ui/ui.html">ui</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Utils Module</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../utils/utils.html">utils</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Adapter Module</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../adapter/adapter.html">adapter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../adapter/adapter.langchain.html">adapter.langchain</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">MCP Module</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../mcp/mcp.html">mcp</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Zerocode Module</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../zerocode/zerocode.html">zerocode</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Edge Module</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../edge/edge.html">edge</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">AgentOpera API References</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">agentopera.models.openai.openai_client</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for agentopera.models.openai.openai_client</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span><span class="w"> </span><span class="nn">asyncio</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">inspect</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">json</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">logging</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">math</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">re</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">asyncio</span><span class="w"> </span><span class="kn">import</span> <span class="n">Task</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">Any</span><span class="p">,</span>
    <span class="n">AsyncGenerator</span><span class="p">,</span>
    <span class="n">Dict</span><span class="p">,</span>
    <span class="n">List</span><span class="p">,</span>
    <span class="n">Mapping</span><span class="p">,</span>
    <span class="n">Optional</span><span class="p">,</span>
    <span class="n">Sequence</span><span class="p">,</span>
    <span class="n">Set</span><span class="p">,</span>
    <span class="n">Type</span><span class="p">,</span>
    <span class="n">Union</span><span class="p">,</span>
    <span class="n">cast</span><span class="p">,</span>
<span class="p">)</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">tiktoken</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">agentopera.engine</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">EVENT_LOGGER_NAME</span><span class="p">,</span>
    <span class="n">TRACE_LOGGER_NAME</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">agentopera.engine.types.image</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">agentopera.engine.function_call</span><span class="w"> </span><span class="kn">import</span> <span class="n">FunctionCall</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">agentopera.engine.types.agent.cancellation_token</span><span class="w"> </span><span class="kn">import</span> <span class="n">CancellationToken</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">agentopera.engine.message_handler_context</span><span class="w"> </span><span class="kn">import</span> <span class="n">MessageHandlerContext</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">agentopera.engine.logging</span><span class="w"> </span><span class="kn">import</span> <span class="n">LLMCallEvent</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">agentopera.engine.types.models</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">AssistantMessage</span><span class="p">,</span>
    <span class="n">ChatCompletionClient</span><span class="p">,</span>
    <span class="n">ChatCompletionTokenLogprob</span><span class="p">,</span>
    <span class="n">CreateResult</span><span class="p">,</span>
    <span class="n">FunctionExecutionResultMessage</span><span class="p">,</span>
    <span class="n">LLMMessage</span><span class="p">,</span>
    <span class="n">ModelCapabilities</span><span class="p">,</span>  <span class="c1"># type: ignore</span>
    <span class="n">ModelFamily</span><span class="p">,</span>
    <span class="n">ModelInfo</span><span class="p">,</span>
    <span class="n">RequestUsage</span><span class="p">,</span>
    <span class="n">SystemMessage</span><span class="p">,</span>
    <span class="n">TopLogprob</span><span class="p">,</span>
    <span class="n">UserMessage</span><span class="p">,</span>
    <span class="n">validate_model_info</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">agentopera.engine.function_call</span><span class="w"> </span><span class="kn">import</span> <span class="n">Tool</span><span class="p">,</span> <span class="n">ToolSchema</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">NOT_GIVEN</span><span class="p">,</span> <span class="n">AsyncAzureOpenAI</span><span class="p">,</span> <span class="n">AsyncOpenAI</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">openai.types.chat</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">ChatCompletion</span><span class="p">,</span>
    <span class="n">ChatCompletionAssistantMessageParam</span><span class="p">,</span>
    <span class="n">ChatCompletionChunk</span><span class="p">,</span>
    <span class="n">ChatCompletionContentPartImageParam</span><span class="p">,</span>
    <span class="n">ChatCompletionContentPartParam</span><span class="p">,</span>
    <span class="n">ChatCompletionContentPartTextParam</span><span class="p">,</span>
    <span class="n">ChatCompletionMessageParam</span><span class="p">,</span>
    <span class="n">ChatCompletionMessageToolCallParam</span><span class="p">,</span>
    <span class="n">ChatCompletionRole</span><span class="p">,</span>
    <span class="n">ChatCompletionSystemMessageParam</span><span class="p">,</span>
    <span class="n">ChatCompletionToolMessageParam</span><span class="p">,</span>
    <span class="n">ChatCompletionToolParam</span><span class="p">,</span>
    <span class="n">ChatCompletionUserMessageParam</span><span class="p">,</span>
    <span class="n">ParsedChatCompletion</span><span class="p">,</span>
    <span class="n">ParsedChoice</span><span class="p">,</span>
    <span class="n">completion_create_params</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">openai.types.chat.chat_completion</span><span class="w"> </span><span class="kn">import</span> <span class="n">Choice</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">openai.types.chat.chat_completion_chunk</span><span class="w"> </span><span class="kn">import</span> <span class="n">Choice</span> <span class="k">as</span> <span class="n">ChunkChoice</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">openai.types.shared_params</span><span class="w"> </span><span class="kn">import</span> <span class="n">FunctionDefinition</span><span class="p">,</span> <span class="n">FunctionParameters</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pydantic</span><span class="w"> </span><span class="kn">import</span> <span class="n">BaseModel</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing_extensions</span><span class="w"> </span><span class="kn">import</span> <span class="n">Self</span><span class="p">,</span> <span class="n">Unpack</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">..utils.normalize_stop_reason</span><span class="w"> </span><span class="kn">import</span> <span class="n">normalize_stop_reason</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">..utils.parse_r1_content</span><span class="w"> </span><span class="kn">import</span> <span class="n">parse_r1_content</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.</span><span class="w"> </span><span class="kn">import</span> <span class="n">model_info_util</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.config</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">AzureOpenAIClientConfiguration</span><span class="p">,</span>
    <span class="n">AzureOpenAIClientConfigurationConfigModel</span><span class="p">,</span>
    <span class="n">OpenAIClientConfiguration</span><span class="p">,</span>
    <span class="n">OpenAIClientConfigurationConfigModel</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="n">EVENT_LOGGER_NAME</span><span class="p">)</span>
<span class="n">trace_logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="n">TRACE_LOGGER_NAME</span><span class="p">)</span>

<span class="n">openai_init_kwargs</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">inspect</span><span class="o">.</span><span class="n">getfullargspec</span><span class="p">(</span><span class="n">AsyncOpenAI</span><span class="o">.</span><span class="fm">__init__</span><span class="p">)</span><span class="o">.</span><span class="n">kwonlyargs</span><span class="p">)</span>
<span class="n">aopenai_init_kwargs</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">inspect</span><span class="o">.</span><span class="n">getfullargspec</span><span class="p">(</span><span class="n">AsyncAzureOpenAI</span><span class="o">.</span><span class="fm">__init__</span><span class="p">)</span><span class="o">.</span><span class="n">kwonlyargs</span><span class="p">)</span>

<span class="n">create_kwargs</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">completion_create_params</span><span class="o">.</span><span class="n">CompletionCreateParamsBase</span><span class="o">.</span><span class="vm">__annotations__</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="o">|</span> <span class="nb">set</span><span class="p">(</span>
    <span class="p">(</span><span class="s2">&quot;timeout&quot;</span><span class="p">,</span> <span class="s2">&quot;stream&quot;</span><span class="p">)</span>
<span class="p">)</span>
<span class="c1"># Only single choice allowed</span>
<span class="n">disallowed_create_args</span> <span class="o">=</span> <span class="nb">set</span><span class="p">([</span><span class="s2">&quot;stream&quot;</span><span class="p">,</span> <span class="s2">&quot;messages&quot;</span><span class="p">,</span> <span class="s2">&quot;function_call&quot;</span><span class="p">,</span> <span class="s2">&quot;functions&quot;</span><span class="p">,</span> <span class="s2">&quot;n&quot;</span><span class="p">])</span>
<span class="n">required_create_args</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="nb">set</span><span class="p">([</span><span class="s2">&quot;model&quot;</span><span class="p">])</span>



<span class="k">def</span><span class="w"> </span><span class="nf">_azure_openai_client_from_config</span><span class="p">(</span><span class="n">config</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">AsyncAzureOpenAI</span><span class="p">:</span>
    <span class="c1"># Take a copy</span>
    <span class="n">copied_config</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">config</span><span class="p">)</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="c1"># Shave down the config to just the AzureOpenAIChatCompletionClient kwargs</span>
    <span class="n">azure_config</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">copied_config</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">aopenai_init_kwargs</span><span class="p">}</span>
    <span class="k">return</span> <span class="n">AsyncAzureOpenAI</span><span class="p">(</span><span class="o">**</span><span class="n">azure_config</span><span class="p">)</span>

<span class="n">MAX_TOOL_CALL_ID_LENGTH</span> <span class="o">=</span> <span class="mi">40</span>

<span class="k">def</span><span class="w"> </span><span class="nf">clip_tool_call_id</span><span class="p">(</span><span class="n">tool_call_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">tool_call_id</span><span class="p">[:</span><span class="n">MAX_TOOL_CALL_ID_LENGTH</span><span class="p">]</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_openai_client_from_config</span><span class="p">(</span><span class="n">config</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">AsyncOpenAI</span><span class="p">:</span>
    <span class="c1"># Shave down the config to just the OpenAI kwargs</span>
    <span class="n">openai_config</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">config</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">openai_init_kwargs</span><span class="p">}</span>
    <span class="k">return</span> <span class="n">AsyncOpenAI</span><span class="p">(</span><span class="o">**</span><span class="n">openai_config</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_create_args_from_config</span><span class="p">(</span><span class="n">config</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
    <span class="n">create_args</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">config</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">create_kwargs</span><span class="p">}</span>
    <span class="n">create_args_keys</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">create_args</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">required_create_args</span><span class="o">.</span><span class="n">issubset</span><span class="p">(</span><span class="n">create_args_keys</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Required create args are missing: </span><span class="si">{</span><span class="n">required_create_args</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">create_args_keys</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">disallowed_create_args</span><span class="o">.</span><span class="n">intersection</span><span class="p">(</span><span class="n">create_args_keys</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Disallowed create args are present: </span><span class="si">{</span><span class="n">disallowed_create_args</span><span class="o">.</span><span class="n">intersection</span><span class="p">(</span><span class="n">create_args_keys</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">create_args</span>


<span class="c1"># TODO check types</span>
<span class="c1"># oai_system_message_schema = type2schema(ChatCompletionSystemMessageParam)</span>
<span class="c1"># oai_user_message_schema = type2schema(ChatCompletionUserMessageParam)</span>
<span class="c1"># oai_assistant_message_schema = type2schema(ChatCompletionAssistantMessageParam)</span>
<span class="c1"># oai_tool_message_schema = type2schema(ChatCompletionToolMessageParam)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">type_to_role</span><span class="p">(</span><span class="n">message</span><span class="p">:</span> <span class="n">LLMMessage</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ChatCompletionRole</span><span class="p">:</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">message</span><span class="p">,</span> <span class="n">SystemMessage</span><span class="p">):</span>
        <span class="k">return</span> <span class="s2">&quot;system&quot;</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">message</span><span class="p">,</span> <span class="n">UserMessage</span><span class="p">):</span>
        <span class="k">return</span> <span class="s2">&quot;user&quot;</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">message</span><span class="p">,</span> <span class="n">AssistantMessage</span><span class="p">):</span>
        <span class="k">return</span> <span class="s2">&quot;assistant&quot;</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="s2">&quot;tool&quot;</span>


<span class="k">def</span><span class="w"> </span><span class="nf">user_message_to_oai</span><span class="p">(</span><span class="n">message</span><span class="p">:</span> <span class="n">UserMessage</span><span class="p">,</span> <span class="n">prepend_name</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ChatCompletionUserMessageParam</span><span class="p">:</span>
    <span class="n">assert_valid_name</span><span class="p">(</span><span class="n">message</span><span class="o">.</span><span class="n">source</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">ChatCompletionUserMessageParam</span><span class="p">(</span>
            <span class="n">content</span><span class="o">=</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">message</span><span class="o">.</span><span class="n">source</span><span class="si">}</span><span class="s2"> said:</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="k">if</span> <span class="n">prepend_name</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="p">,</span>
            <span class="n">role</span><span class="o">=</span><span class="s2">&quot;user&quot;</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="n">message</span><span class="o">.</span><span class="n">source</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">parts</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">ChatCompletionContentPartParam</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">part</span> <span class="ow">in</span> <span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">part</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">prepend_name</span><span class="p">:</span>
                    <span class="c1"># Append the name to the first text part</span>
                    <span class="n">oai_part</span> <span class="o">=</span> <span class="n">ChatCompletionContentPartTextParam</span><span class="p">(</span>
                        <span class="n">text</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">message</span><span class="o">.</span><span class="n">source</span><span class="si">}</span><span class="s2"> said:</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="n">part</span><span class="p">,</span>
                        <span class="nb">type</span><span class="o">=</span><span class="s2">&quot;text&quot;</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="n">prepend_name</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">oai_part</span> <span class="o">=</span> <span class="n">ChatCompletionContentPartTextParam</span><span class="p">(</span>
                        <span class="n">text</span><span class="o">=</span><span class="n">part</span><span class="p">,</span>
                        <span class="nb">type</span><span class="o">=</span><span class="s2">&quot;text&quot;</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="n">parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">oai_part</span><span class="p">)</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">part</span><span class="p">,</span> <span class="n">Image</span><span class="p">):</span>
                <span class="c1"># TODO: support url based images</span>
                <span class="c1"># TODO: support specifying details</span>
                <span class="n">parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cast</span><span class="p">(</span><span class="n">ChatCompletionContentPartImageParam</span><span class="p">,</span> <span class="n">part</span><span class="o">.</span><span class="n">to_openai_format</span><span class="p">()))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown content type: </span><span class="si">{</span><span class="n">part</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ChatCompletionUserMessageParam</span><span class="p">(</span>
            <span class="n">content</span><span class="o">=</span><span class="n">parts</span><span class="p">,</span>
            <span class="n">role</span><span class="o">=</span><span class="s2">&quot;user&quot;</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="n">message</span><span class="o">.</span><span class="n">source</span><span class="p">,</span>
        <span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">system_message_to_oai</span><span class="p">(</span><span class="n">message</span><span class="p">:</span> <span class="n">SystemMessage</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ChatCompletionSystemMessageParam</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">ChatCompletionSystemMessageParam</span><span class="p">(</span>
        <span class="n">content</span><span class="o">=</span><span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="p">,</span>
        <span class="n">role</span><span class="o">=</span><span class="s2">&quot;system&quot;</span><span class="p">,</span>
    <span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">func_call_to_oai</span><span class="p">(</span><span class="n">message</span><span class="p">:</span> <span class="n">FunctionCall</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ChatCompletionMessageToolCallParam</span><span class="p">:</span>
    <span class="c1"># Ensure toolCallId doesn&#39;t exceed OpenAI&#39;s 40-char limit</span>
    <span class="n">safe_id</span> <span class="o">=</span> <span class="n">clip_tool_call_id</span><span class="p">(</span><span class="n">message</span><span class="o">.</span><span class="n">id</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ChatCompletionMessageToolCallParam</span><span class="p">(</span>
        <span class="nb">id</span><span class="o">=</span><span class="n">safe_id</span><span class="p">,</span>
        <span class="n">function</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;arguments&quot;</span><span class="p">:</span> <span class="n">message</span><span class="o">.</span><span class="n">arguments</span><span class="p">,</span>
            <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="n">message</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
        <span class="p">},</span>
        <span class="nb">type</span><span class="o">=</span><span class="s2">&quot;function&quot;</span><span class="p">,</span>
    <span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">tool_message_to_oai</span><span class="p">(</span>
    <span class="n">message</span><span class="p">:</span> <span class="n">FunctionExecutionResultMessage</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">ChatCompletionToolMessageParam</span><span class="p">]:</span>
    <span class="k">return</span> <span class="p">[</span>
        <span class="n">ChatCompletionToolMessageParam</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">content</span><span class="p">,</span> <span class="n">role</span><span class="o">=</span><span class="s2">&quot;tool&quot;</span><span class="p">,</span> <span class="n">tool_call_id</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">call_id</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">message</span><span class="o">.</span><span class="n">content</span>
    <span class="p">]</span>


<span class="k">def</span><span class="w"> </span><span class="nf">assistant_message_to_oai</span><span class="p">(</span>
    <span class="n">message</span><span class="p">:</span> <span class="n">AssistantMessage</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ChatCompletionAssistantMessageParam</span><span class="p">:</span>
    <span class="n">assert_valid_name</span><span class="p">(</span><span class="n">message</span><span class="o">.</span><span class="n">source</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">message</span><span class="o">.</span><span class="n">thought</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">ChatCompletionAssistantMessageParam</span><span class="p">(</span>
                <span class="n">content</span><span class="o">=</span><span class="n">message</span><span class="o">.</span><span class="n">thought</span><span class="p">,</span>
                <span class="n">tool_calls</span><span class="o">=</span><span class="p">[</span><span class="n">func_call_to_oai</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="p">],</span>
                <span class="n">role</span><span class="o">=</span><span class="s2">&quot;assistant&quot;</span><span class="p">,</span>
                <span class="n">name</span><span class="o">=</span><span class="n">message</span><span class="o">.</span><span class="n">source</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">ChatCompletionAssistantMessageParam</span><span class="p">(</span>
                <span class="n">tool_calls</span><span class="o">=</span><span class="p">[</span><span class="n">func_call_to_oai</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="p">],</span>
                <span class="n">role</span><span class="o">=</span><span class="s2">&quot;assistant&quot;</span><span class="p">,</span>
                <span class="n">name</span><span class="o">=</span><span class="n">message</span><span class="o">.</span><span class="n">source</span><span class="p">,</span>
            <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">ChatCompletionAssistantMessageParam</span><span class="p">(</span>
            <span class="n">content</span><span class="o">=</span><span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="p">,</span>
            <span class="n">role</span><span class="o">=</span><span class="s2">&quot;assistant&quot;</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="n">message</span><span class="o">.</span><span class="n">source</span><span class="p">,</span>
        <span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">to_oai_type</span><span class="p">(</span><span class="n">message</span><span class="p">:</span> <span class="n">LLMMessage</span><span class="p">,</span> <span class="n">prepend_name</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">ChatCompletionMessageParam</span><span class="p">]:</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">message</span><span class="p">,</span> <span class="n">SystemMessage</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">system_message_to_oai</span><span class="p">(</span><span class="n">message</span><span class="p">)]</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">message</span><span class="p">,</span> <span class="n">UserMessage</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">user_message_to_oai</span><span class="p">(</span><span class="n">message</span><span class="p">,</span> <span class="n">prepend_name</span><span class="p">)]</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">message</span><span class="p">,</span> <span class="n">AssistantMessage</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">assistant_message_to_oai</span><span class="p">(</span><span class="n">message</span><span class="p">)]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">tool_message_to_oai</span><span class="p">(</span><span class="n">message</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">calculate_vision_tokens</span><span class="p">(</span><span class="n">image</span><span class="p">:</span> <span class="n">Image</span><span class="p">,</span> <span class="n">detail</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;auto&quot;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="n">MAX_LONG_EDGE</span> <span class="o">=</span> <span class="mi">2048</span>
    <span class="n">BASE_TOKEN_COUNT</span> <span class="o">=</span> <span class="mi">85</span>
    <span class="n">TOKENS_PER_TILE</span> <span class="o">=</span> <span class="mi">170</span>
    <span class="n">MAX_SHORT_EDGE</span> <span class="o">=</span> <span class="mi">768</span>
    <span class="n">TILE_SIZE</span> <span class="o">=</span> <span class="mi">512</span>

    <span class="k">if</span> <span class="n">detail</span> <span class="o">==</span> <span class="s2">&quot;low&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">BASE_TOKEN_COUNT</span>

    <span class="n">width</span><span class="p">,</span> <span class="n">height</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">size</span>

    <span class="c1"># Scale down to fit within a MAX_LONG_EDGE x MAX_LONG_EDGE square if necessary</span>

    <span class="k">if</span> <span class="n">width</span> <span class="o">&gt;</span> <span class="n">MAX_LONG_EDGE</span> <span class="ow">or</span> <span class="n">height</span> <span class="o">&gt;</span> <span class="n">MAX_LONG_EDGE</span><span class="p">:</span>
        <span class="n">aspect_ratio</span> <span class="o">=</span> <span class="n">width</span> <span class="o">/</span> <span class="n">height</span>
        <span class="k">if</span> <span class="n">aspect_ratio</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># Width is greater than height</span>
            <span class="n">width</span> <span class="o">=</span> <span class="n">MAX_LONG_EDGE</span>
            <span class="n">height</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">MAX_LONG_EDGE</span> <span class="o">/</span> <span class="n">aspect_ratio</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Height is greater than or equal to width</span>
            <span class="n">height</span> <span class="o">=</span> <span class="n">MAX_LONG_EDGE</span>
            <span class="n">width</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">MAX_LONG_EDGE</span> <span class="o">*</span> <span class="n">aspect_ratio</span><span class="p">)</span>

    <span class="c1"># Resize such that the shortest side is MAX_SHORT_EDGE if both dimensions exceed MAX_SHORT_EDGE</span>
    <span class="n">aspect_ratio</span> <span class="o">=</span> <span class="n">width</span> <span class="o">/</span> <span class="n">height</span>
    <span class="k">if</span> <span class="n">width</span> <span class="o">&gt;</span> <span class="n">MAX_SHORT_EDGE</span> <span class="ow">and</span> <span class="n">height</span> <span class="o">&gt;</span> <span class="n">MAX_SHORT_EDGE</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">aspect_ratio</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># Width is greater than height</span>
            <span class="n">height</span> <span class="o">=</span> <span class="n">MAX_SHORT_EDGE</span>
            <span class="n">width</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">MAX_SHORT_EDGE</span> <span class="o">*</span> <span class="n">aspect_ratio</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Height is greater than or equal to width</span>
            <span class="n">width</span> <span class="o">=</span> <span class="n">MAX_SHORT_EDGE</span>
            <span class="n">height</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">MAX_SHORT_EDGE</span> <span class="o">/</span> <span class="n">aspect_ratio</span><span class="p">)</span>

    <span class="c1"># Calculate the number of tiles based on TILE_SIZE</span>

    <span class="n">tiles_width</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">width</span> <span class="o">/</span> <span class="n">TILE_SIZE</span><span class="p">)</span>
    <span class="n">tiles_height</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">height</span> <span class="o">/</span> <span class="n">TILE_SIZE</span><span class="p">)</span>
    <span class="n">total_tiles</span> <span class="o">=</span> <span class="n">tiles_width</span> <span class="o">*</span> <span class="n">tiles_height</span>
    <span class="c1"># Calculate the total tokens based on the number of tiles and the base token count</span>

    <span class="n">total_tokens</span> <span class="o">=</span> <span class="n">BASE_TOKEN_COUNT</span> <span class="o">+</span> <span class="n">TOKENS_PER_TILE</span> <span class="o">*</span> <span class="n">total_tiles</span>

    <span class="k">return</span> <span class="n">total_tokens</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_add_usage</span><span class="p">(</span><span class="n">usage1</span><span class="p">:</span> <span class="n">RequestUsage</span><span class="p">,</span> <span class="n">usage2</span><span class="p">:</span> <span class="n">RequestUsage</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RequestUsage</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">RequestUsage</span><span class="p">(</span>
        <span class="n">prompt_tokens</span><span class="o">=</span><span class="n">usage1</span><span class="o">.</span><span class="n">prompt_tokens</span> <span class="o">+</span> <span class="n">usage2</span><span class="o">.</span><span class="n">prompt_tokens</span><span class="p">,</span>
        <span class="n">completion_tokens</span><span class="o">=</span><span class="n">usage1</span><span class="o">.</span><span class="n">completion_tokens</span> <span class="o">+</span> <span class="n">usage2</span><span class="o">.</span><span class="n">completion_tokens</span><span class="p">,</span>
    <span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">convert_tools</span><span class="p">(</span>
    <span class="n">tools</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Tool</span> <span class="o">|</span> <span class="n">ToolSchema</span><span class="p">],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">ChatCompletionToolParam</span><span class="p">]:</span>
    <span class="n">result</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">ChatCompletionToolParam</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">tool</span> <span class="ow">in</span> <span class="n">tools</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tool</span><span class="p">,</span> <span class="n">Tool</span><span class="p">):</span>
            <span class="n">tool_schema</span> <span class="o">=</span> <span class="n">tool</span><span class="o">.</span><span class="n">schema</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tool</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span>
            <span class="n">tool_schema</span> <span class="o">=</span> <span class="n">tool</span>

        <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">ChatCompletionToolParam</span><span class="p">(</span>
                <span class="nb">type</span><span class="o">=</span><span class="s2">&quot;function&quot;</span><span class="p">,</span>
                <span class="n">function</span><span class="o">=</span><span class="n">FunctionDefinition</span><span class="p">(</span>
                    <span class="n">name</span><span class="o">=</span><span class="n">tool_schema</span><span class="p">[</span><span class="s2">&quot;name&quot;</span><span class="p">],</span>
                    <span class="n">description</span><span class="o">=</span><span class="p">(</span><span class="n">tool_schema</span><span class="p">[</span><span class="s2">&quot;description&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="s2">&quot;description&quot;</span> <span class="ow">in</span> <span class="n">tool_schema</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span><span class="p">),</span>
                    <span class="n">parameters</span><span class="o">=</span><span class="p">(</span>
                        <span class="n">cast</span><span class="p">(</span><span class="n">FunctionParameters</span><span class="p">,</span> <span class="n">tool_schema</span><span class="p">[</span><span class="s2">&quot;parameters&quot;</span><span class="p">])</span> <span class="k">if</span> <span class="s2">&quot;parameters&quot;</span> <span class="ow">in</span> <span class="n">tool_schema</span> <span class="k">else</span> <span class="p">{}</span>
                    <span class="p">),</span>
                    <span class="n">strict</span><span class="o">=</span><span class="p">(</span><span class="n">tool_schema</span><span class="p">[</span><span class="s2">&quot;strict&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="s2">&quot;strict&quot;</span> <span class="ow">in</span> <span class="n">tool_schema</span> <span class="k">else</span> <span class="kc">False</span><span class="p">),</span>
                <span class="p">),</span>
            <span class="p">)</span>
        <span class="p">)</span>
    <span class="c1"># Check if all tools have valid names.</span>
    <span class="k">for</span> <span class="n">tool_param</span> <span class="ow">in</span> <span class="n">result</span><span class="p">:</span>
        <span class="n">assert_valid_name</span><span class="p">(</span><span class="n">tool_param</span><span class="p">[</span><span class="s2">&quot;function&quot;</span><span class="p">][</span><span class="s2">&quot;name&quot;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">result</span>


<span class="k">def</span><span class="w"> </span><span class="nf">normalize_name</span><span class="p">(</span><span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    LLMs sometimes ask functions while ignoring their own format requirements, this function should be used to replace invalid characters with &quot;_&quot;.</span>

<span class="sd">    Prefer _assert_valid_name for validating user configuration or input</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;[^a-zA-Z0-9_-]&quot;</span><span class="p">,</span> <span class="s2">&quot;_&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">)[:</span><span class="mi">64</span><span class="p">]</span>


<span class="k">def</span><span class="w"> </span><span class="nf">assert_valid_name</span><span class="p">(</span><span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Ensure that configured names are valid, raises ValueError if not.</span>

<span class="sd">    For munging LLM responses use _normalize_name to ensure LLM specified names don&#39;t break the API.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;^[a-zA-Z0-9_-]+$&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid name: </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">. Only letters, numbers, &#39;_&#39; and &#39;-&#39; are allowed.&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">name</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">64</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid name: </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">. Name must be less than 64 characters.&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">name</span>


<div class="viewcode-block" id="BaseOpenAIChatCompletionClient">
<a class="viewcode-back" href="../../../../models/models.openai.html#agentopera.models.openai.BaseOpenAIChatCompletionClient">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">BaseOpenAIChatCompletionClient</span><span class="p">(</span><span class="n">ChatCompletionClient</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">client</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">AsyncOpenAI</span><span class="p">,</span> <span class="n">AsyncAzureOpenAI</span><span class="p">],</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">create_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
        <span class="n">model_capabilities</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ModelCapabilities</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># type: ignore</span>
        <span class="n">model_info</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ModelInfo</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">add_name_prefixes</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_client</span> <span class="o">=</span> <span class="n">client</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_add_name_prefixes</span> <span class="o">=</span> <span class="n">add_name_prefixes</span>
        <span class="k">if</span> <span class="n">model_capabilities</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">model_info</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_model_info</span> <span class="o">=</span> <span class="n">model_info_util</span><span class="o">.</span><span class="n">get_info</span><span class="p">(</span><span class="n">create_args</span><span class="p">[</span><span class="s2">&quot;model&quot;</span><span class="p">])</span>
            <span class="k">except</span> <span class="ne">KeyError</span> <span class="k">as</span> <span class="n">err</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;model_info is required when model name is not a valid OpenAI model&quot;</span><span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">err</span>
        <span class="k">elif</span> <span class="n">model_capabilities</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">model_info</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;model_capabilities and model_info are mutually exclusive&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">model_capabilities</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">model_info</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;model_capabilities is deprecated, use model_info instead&quot;</span><span class="p">,</span> <span class="ne">DeprecationWarning</span><span class="p">,</span> <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">info</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">ModelInfo</span><span class="p">,</span> <span class="n">model_capabilities</span><span class="p">)</span>
            <span class="n">info</span><span class="p">[</span><span class="s2">&quot;family&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ModelFamily</span><span class="o">.</span><span class="n">UNKNOWN</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_model_info</span> <span class="o">=</span> <span class="n">info</span>
        <span class="k">elif</span> <span class="n">model_capabilities</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">model_info</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_model_info</span> <span class="o">=</span> <span class="n">model_info</span>

        <span class="c1"># Validate model_info, check if all required fields are present</span>
        <span class="n">validate_model_info</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_model_info</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_resolved_model</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="s2">&quot;model&quot;</span> <span class="ow">in</span> <span class="n">create_args</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_resolved_model</span> <span class="o">=</span> <span class="n">model_info_util</span><span class="o">.</span><span class="n">resolve_model</span><span class="p">(</span><span class="n">create_args</span><span class="p">[</span><span class="s2">&quot;model&quot;</span><span class="p">])</span>

        <span class="k">if</span> <span class="p">(</span>
            <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_info</span><span class="p">[</span><span class="s2">&quot;json_output&quot;</span><span class="p">]</span>
            <span class="ow">and</span> <span class="s2">&quot;response_format&quot;</span> <span class="ow">in</span> <span class="n">create_args</span>
            <span class="ow">and</span> <span class="p">(</span>
                <span class="nb">isinstance</span><span class="p">(</span><span class="n">create_args</span><span class="p">[</span><span class="s2">&quot;response_format&quot;</span><span class="p">],</span> <span class="nb">dict</span><span class="p">)</span>
                <span class="ow">and</span> <span class="n">create_args</span><span class="p">[</span><span class="s2">&quot;response_format&quot;</span><span class="p">][</span><span class="s2">&quot;type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;json_object&quot;</span>
            <span class="p">)</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Model does not support JSON output.&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_create_args</span> <span class="o">=</span> <span class="n">create_args</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_total_usage</span> <span class="o">=</span> <span class="n">RequestUsage</span><span class="p">(</span><span class="n">prompt_tokens</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">completion_tokens</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_actual_usage</span> <span class="o">=</span> <span class="n">RequestUsage</span><span class="p">(</span><span class="n">prompt_tokens</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">completion_tokens</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<div class="viewcode-block" id="BaseOpenAIChatCompletionClient.create_from_config">
<a class="viewcode-back" href="../../../../models/models.openai.html#agentopera.models.openai.BaseOpenAIChatCompletionClient.create_from_config">[docs]</a>
    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">create_from_config</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">ChatCompletionClient</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">OpenAIChatCompletionClient</span><span class="p">(</span><span class="o">**</span><span class="n">config</span><span class="p">)</span></div>


<div class="viewcode-block" id="BaseOpenAIChatCompletionClient.create">
<a class="viewcode-back" href="../../../../models/models.openai.html#agentopera.models.openai.BaseOpenAIChatCompletionClient.create">[docs]</a>
    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">create</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">messages</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">LLMMessage</span><span class="p">],</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">tools</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Tool</span> <span class="o">|</span> <span class="n">ToolSchema</span><span class="p">]</span> <span class="o">=</span> <span class="p">[],</span>
        <span class="n">json_output</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">extra_create_args</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="p">{},</span>
        <span class="n">cancellation_token</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">CancellationToken</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">CreateResult</span><span class="p">:</span>
        <span class="c1"># Make sure all extra_create_args are valid</span>
        <span class="n">extra_create_args_keys</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">extra_create_args</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">create_kwargs</span><span class="o">.</span><span class="n">issuperset</span><span class="p">(</span><span class="n">extra_create_args_keys</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Extra create args are invalid: </span><span class="si">{</span><span class="n">extra_create_args_keys</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">create_kwargs</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Copy the create args and overwrite anything in extra_create_args</span>
        <span class="n">create_args</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_args</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">create_args</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">extra_create_args</span><span class="p">)</span>

        <span class="c1"># Declare use_beta_client</span>
        <span class="n">use_beta_client</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">response_format_value</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Type</span><span class="p">[</span><span class="n">BaseModel</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="s2">&quot;response_format&quot;</span> <span class="ow">in</span> <span class="n">create_args</span><span class="p">:</span>
            <span class="n">value</span> <span class="o">=</span> <span class="n">create_args</span><span class="p">[</span><span class="s2">&quot;response_format&quot;</span><span class="p">]</span>
            <span class="c1"># If value is a Pydantic model class, use the beta client</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">type</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">issubclass</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">BaseModel</span><span class="p">):</span>
                <span class="n">response_format_value</span> <span class="o">=</span> <span class="n">value</span>
                <span class="n">use_beta_client</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># response_format_value is not a Pydantic model class</span>
                <span class="n">use_beta_client</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="n">response_format_value</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Remove &#39;response_format&#39; from create_args to prevent passing it twice</span>
        <span class="n">create_args_no_response_format</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">create_args</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span> <span class="o">!=</span> <span class="s2">&quot;response_format&quot;</span><span class="p">}</span>

        <span class="c1"># TODO: allow custom handling.</span>
        <span class="c1"># For now we raise an error if images are present and vision is not supported</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_info</span><span class="p">[</span><span class="s2">&quot;vision&quot;</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">message</span> <span class="ow">in</span> <span class="n">messages</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">message</span><span class="p">,</span> <span class="n">UserMessage</span><span class="p">):</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">any</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Image</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="p">):</span>
                        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Model does not support vision and image was provided&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">json_output</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_info</span><span class="p">[</span><span class="s2">&quot;json_output&quot;</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">False</span> <span class="ow">and</span> <span class="n">json_output</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Model does not support JSON output.&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">json_output</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                <span class="n">create_args</span><span class="p">[</span><span class="s2">&quot;response_format&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;json_object&quot;</span><span class="p">}</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">create_args</span><span class="p">[</span><span class="s2">&quot;response_format&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;text&quot;</span><span class="p">}</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_info</span><span class="p">[</span><span class="s2">&quot;json_output&quot;</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">False</span> <span class="ow">and</span> <span class="n">json_output</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Model does not support JSON output.&quot;</span><span class="p">)</span>

        <span class="n">oai_messages_nested</span> <span class="o">=</span> <span class="p">[</span><span class="n">to_oai_type</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">prepend_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_add_name_prefixes</span><span class="p">)</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">messages</span><span class="p">]</span>
        <span class="n">oai_messages</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span> <span class="k">for</span> <span class="n">sublist</span> <span class="ow">in</span> <span class="n">oai_messages_nested</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">sublist</span><span class="p">]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_info</span><span class="p">[</span><span class="s2">&quot;function_calling&quot;</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">False</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">tools</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Model does not support function calling&quot;</span><span class="p">)</span>
        <span class="n">future</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Task</span><span class="p">[</span><span class="n">ParsedChatCompletion</span><span class="p">[</span><span class="n">BaseModel</span><span class="p">]],</span> <span class="n">Task</span><span class="p">[</span><span class="n">ChatCompletion</span><span class="p">]]</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">tools</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">converted_tools</span> <span class="o">=</span> <span class="n">convert_tools</span><span class="p">(</span><span class="n">tools</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">use_beta_client</span><span class="p">:</span>
                <span class="c1"># Pass response_format_value if it&#39;s not None</span>
                <span class="k">if</span> <span class="n">response_format_value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">future</span> <span class="o">=</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">ensure_future</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_client</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span>
                            <span class="n">messages</span><span class="o">=</span><span class="n">oai_messages</span><span class="p">,</span>
                            <span class="n">tools</span><span class="o">=</span><span class="n">converted_tools</span><span class="p">,</span>
                            <span class="n">response_format</span><span class="o">=</span><span class="n">response_format_value</span><span class="p">,</span>
                            <span class="o">**</span><span class="n">create_args_no_response_format</span><span class="p">,</span>
                        <span class="p">)</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">future</span> <span class="o">=</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">ensure_future</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_client</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span>
                            <span class="n">messages</span><span class="o">=</span><span class="n">oai_messages</span><span class="p">,</span>
                            <span class="n">tools</span><span class="o">=</span><span class="n">converted_tools</span><span class="p">,</span>
                            <span class="o">**</span><span class="n">create_args_no_response_format</span><span class="p">,</span>
                        <span class="p">)</span>
                    <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">future</span> <span class="o">=</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">ensure_future</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
                        <span class="n">messages</span><span class="o">=</span><span class="n">oai_messages</span><span class="p">,</span>
                        <span class="n">stream</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="n">tools</span><span class="o">=</span><span class="n">converted_tools</span><span class="p">,</span>
                        <span class="o">**</span><span class="n">create_args</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">use_beta_client</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">response_format_value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">future</span> <span class="o">=</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">ensure_future</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_client</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span>
                            <span class="n">messages</span><span class="o">=</span><span class="n">oai_messages</span><span class="p">,</span>
                            <span class="n">response_format</span><span class="o">=</span><span class="n">response_format_value</span><span class="p">,</span>
                            <span class="o">**</span><span class="n">create_args_no_response_format</span><span class="p">,</span>
                        <span class="p">)</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">future</span> <span class="o">=</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">ensure_future</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_client</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span>
                            <span class="n">messages</span><span class="o">=</span><span class="n">oai_messages</span><span class="p">,</span>
                            <span class="o">**</span><span class="n">create_args_no_response_format</span><span class="p">,</span>
                        <span class="p">)</span>
                    <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">future</span> <span class="o">=</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">ensure_future</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
                        <span class="n">messages</span><span class="o">=</span><span class="n">oai_messages</span><span class="p">,</span>
                        <span class="n">stream</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="o">**</span><span class="n">create_args</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="p">)</span>

        <span class="k">if</span> <span class="n">cancellation_token</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">cancellation_token</span><span class="o">.</span><span class="n">link_future</span><span class="p">(</span><span class="n">future</span><span class="p">)</span>
        <span class="n">result</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ParsedChatCompletion</span><span class="p">[</span><span class="n">BaseModel</span><span class="p">],</span> <span class="n">ChatCompletion</span><span class="p">]</span> <span class="o">=</span> <span class="k">await</span> <span class="n">future</span>
        <span class="k">if</span> <span class="n">use_beta_client</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">ParsedChatCompletion</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span> <span class="n">result</span><span class="p">)</span>

        <span class="n">usage</span> <span class="o">=</span> <span class="n">RequestUsage</span><span class="p">(</span>
            <span class="c1"># TODO backup token counting</span>
            <span class="n">prompt_tokens</span><span class="o">=</span><span class="n">result</span><span class="o">.</span><span class="n">usage</span><span class="o">.</span><span class="n">prompt_tokens</span> <span class="k">if</span> <span class="n">result</span><span class="o">.</span><span class="n">usage</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span>
            <span class="n">completion_tokens</span><span class="o">=</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">usage</span><span class="o">.</span><span class="n">completion_tokens</span> <span class="k">if</span> <span class="n">result</span><span class="o">.</span><span class="n">usage</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">0</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="c1"># If we are running in the context of a handler we can get the agent_id</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">agent_id</span> <span class="o">=</span> <span class="n">MessageHandlerContext</span><span class="o">.</span><span class="n">agent_id</span><span class="p">()</span>
        <span class="k">except</span> <span class="ne">RuntimeError</span><span class="p">:</span>
            <span class="n">agent_id</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="n">LLMCallEvent</span><span class="p">(</span>
                <span class="n">messages</span><span class="o">=</span><span class="n">cast</span><span class="p">(</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">oai_messages</span><span class="p">),</span>
                <span class="n">response</span><span class="o">=</span><span class="n">result</span><span class="o">.</span><span class="n">model_dump</span><span class="p">(),</span>
                <span class="n">prompt_tokens</span><span class="o">=</span><span class="n">usage</span><span class="o">.</span><span class="n">prompt_tokens</span><span class="p">,</span>
                <span class="n">completion_tokens</span><span class="o">=</span><span class="n">usage</span><span class="o">.</span><span class="n">completion_tokens</span><span class="p">,</span>
                <span class="n">agent_id</span><span class="o">=</span><span class="n">agent_id</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_resolved_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_resolved_model</span> <span class="o">!=</span> <span class="n">result</span><span class="o">.</span><span class="n">model</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Resolved model mismatch: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_resolved_model</span><span class="si">}</span><span class="s2"> != </span><span class="si">{</span><span class="n">result</span><span class="o">.</span><span class="n">model</span><span class="si">}</span><span class="s2">. &quot;</span>
                    <span class="s2">&quot;Model mapping in agentopera.agents.models.openai may be incorrect. &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Set the model to </span><span class="si">{</span><span class="n">result</span><span class="o">.</span><span class="n">model</span><span class="si">}</span><span class="s2"> to enhance token/cost estimation and suppress this warning.&quot;</span><span class="p">,</span>
                    <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                <span class="p">)</span>

        <span class="c1"># Limited to a single choice currently.</span>
        <span class="n">choice</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ParsedChoice</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span> <span class="n">ParsedChoice</span><span class="p">[</span><span class="n">BaseModel</span><span class="p">],</span> <span class="n">Choice</span><span class="p">]</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># Detect whether it is a function call or not.</span>
        <span class="c1"># We don&#39;t rely on choice.finish_reason as it is not always accurate, depending on the API used.</span>
        <span class="n">content</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">FunctionCall</span><span class="p">]]</span>
        <span class="n">thought</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">choice</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">function_call</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;function_call is deprecated and is not supported by this model client.&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">choice</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">tool_calls</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">choice</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">tool_calls</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">choice</span><span class="o">.</span><span class="n">finish_reason</span> <span class="o">!=</span> <span class="s2">&quot;tool_calls&quot;</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Finish reason mismatch: </span><span class="si">{</span><span class="n">choice</span><span class="o">.</span><span class="n">finish_reason</span><span class="si">}</span><span class="s2"> != tool_calls &quot;</span>
                    <span class="s2">&quot;when tool_calls are present. Finish reason may not be accurate. &quot;</span>
                    <span class="s2">&quot;This may be due to the API used that is not returning the correct finish reason.&quot;</span><span class="p">,</span>
                    <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">choice</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">choice</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span> <span class="o">!=</span> <span class="s2">&quot;&quot;</span><span class="p">:</span>
                <span class="c1"># Put the content in the thought field.</span>
                <span class="n">thought</span> <span class="o">=</span> <span class="n">choice</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span>
            <span class="c1"># NOTE: If OAI response type changes, this will need to be updated</span>
            <span class="n">content</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">tool_call</span> <span class="ow">in</span> <span class="n">choice</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">tool_calls</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tool_call</span><span class="o">.</span><span class="n">function</span><span class="o">.</span><span class="n">arguments</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Tool call function arguments field is not a string: </span><span class="si">{</span><span class="n">tool_call</span><span class="o">.</span><span class="n">function</span><span class="o">.</span><span class="n">arguments</span><span class="si">}</span><span class="s2">.&quot;</span>
                        <span class="s2">&quot;This is unexpected and may due to the API used not returning the correct type. &quot;</span>
                        <span class="s2">&quot;Attempting to convert it to string.&quot;</span><span class="p">,</span>
                        <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tool_call</span><span class="o">.</span><span class="n">function</span><span class="o">.</span><span class="n">arguments</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                        <span class="n">tool_call</span><span class="o">.</span><span class="n">function</span><span class="o">.</span><span class="n">arguments</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">tool_call</span><span class="o">.</span><span class="n">function</span><span class="o">.</span><span class="n">arguments</span><span class="p">)</span>
                <span class="n">content</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="n">FunctionCall</span><span class="p">(</span>
                        <span class="nb">id</span><span class="o">=</span><span class="n">clip_tool_call_id</span><span class="p">(</span><span class="n">tool_call</span><span class="o">.</span><span class="n">id</span><span class="p">),</span>
                        <span class="n">arguments</span><span class="o">=</span><span class="n">tool_call</span><span class="o">.</span><span class="n">function</span><span class="o">.</span><span class="n">arguments</span><span class="p">,</span>
                        <span class="n">name</span><span class="o">=</span><span class="n">normalize_name</span><span class="p">(</span><span class="n">tool_call</span><span class="o">.</span><span class="n">function</span><span class="o">.</span><span class="n">name</span><span class="p">),</span>
                    <span class="p">)</span>
                <span class="p">)</span>
            <span class="n">finish_reason</span> <span class="o">=</span> <span class="s2">&quot;tool_calls&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">finish_reason</span> <span class="o">=</span> <span class="n">choice</span><span class="o">.</span><span class="n">finish_reason</span>
            <span class="n">content</span> <span class="o">=</span> <span class="n">choice</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span> <span class="ow">or</span> <span class="s2">&quot;&quot;</span>

        <span class="n">logprobs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">ChatCompletionTokenLogprob</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">choice</span><span class="o">.</span><span class="n">logprobs</span> <span class="ow">and</span> <span class="n">choice</span><span class="o">.</span><span class="n">logprobs</span><span class="o">.</span><span class="n">content</span><span class="p">:</span>
            <span class="n">logprobs</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">ChatCompletionTokenLogprob</span><span class="p">(</span>
                    <span class="n">token</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">token</span><span class="p">,</span>
                    <span class="n">logprob</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">logprob</span><span class="p">,</span>
                    <span class="n">top_logprobs</span><span class="o">=</span><span class="p">[</span><span class="n">TopLogprob</span><span class="p">(</span><span class="n">logprob</span><span class="o">=</span><span class="n">y</span><span class="o">.</span><span class="n">logprob</span><span class="p">,</span> <span class="nb">bytes</span><span class="o">=</span><span class="n">y</span><span class="o">.</span><span class="n">bytes</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">x</span><span class="o">.</span><span class="n">top_logprobs</span><span class="p">],</span>
                    <span class="nb">bytes</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">bytes</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">choice</span><span class="o">.</span><span class="n">logprobs</span><span class="o">.</span><span class="n">content</span>
            <span class="p">]</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">content</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_info</span><span class="p">[</span><span class="s2">&quot;family&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">ModelFamily</span><span class="o">.</span><span class="n">R1</span><span class="p">:</span>
            <span class="n">thought</span><span class="p">,</span> <span class="n">content</span> <span class="o">=</span> <span class="n">parse_r1_content</span><span class="p">(</span><span class="n">content</span><span class="p">)</span>

        <span class="n">response</span> <span class="o">=</span> <span class="n">CreateResult</span><span class="p">(</span>
            <span class="n">finish_reason</span><span class="o">=</span><span class="n">normalize_stop_reason</span><span class="p">(</span><span class="n">finish_reason</span><span class="p">),</span>
            <span class="n">content</span><span class="o">=</span><span class="n">content</span><span class="p">,</span>
            <span class="n">usage</span><span class="o">=</span><span class="n">usage</span><span class="p">,</span>
            <span class="n">cached</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">logprobs</span><span class="o">=</span><span class="n">logprobs</span><span class="p">,</span>
            <span class="n">thought</span><span class="o">=</span><span class="n">thought</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_total_usage</span> <span class="o">=</span> <span class="n">_add_usage</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_total_usage</span><span class="p">,</span> <span class="n">usage</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_actual_usage</span> <span class="o">=</span> <span class="n">_add_usage</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_actual_usage</span><span class="p">,</span> <span class="n">usage</span><span class="p">)</span>

        <span class="c1"># TODO - why is this cast needed?</span>
        <span class="k">return</span> <span class="n">response</span></div>


<div class="viewcode-block" id="BaseOpenAIChatCompletionClient.create_stream">
<a class="viewcode-back" href="../../../../models/models.openai.html#agentopera.models.openai.BaseOpenAIChatCompletionClient.create_stream">[docs]</a>
    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">create_stream</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">messages</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">LLMMessage</span><span class="p">],</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">tools</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Tool</span> <span class="o">|</span> <span class="n">ToolSchema</span><span class="p">]</span> <span class="o">=</span> <span class="p">[],</span>
        <span class="n">json_output</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">extra_create_args</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="p">{},</span>
        <span class="n">cancellation_token</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">CancellationToken</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">max_consecutive_empty_chunk_tolerance</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">AsyncGenerator</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">CreateResult</span><span class="p">],</span> <span class="kc">None</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Creates an AsyncGenerator that will yield a  stream of chat completions based on the provided messages and tools.</span>

<span class="sd">        Args:</span>
<span class="sd">            messages (Sequence[LLMMessage]): A sequence of messages to be processed.</span>
<span class="sd">            tools (Sequence[Tool | ToolSchema], optional): A sequence of tools to be used in the completion. Defaults to `[]`.</span>
<span class="sd">            json_output (Optional[bool], optional): If True, the output will be in JSON format. Defaults to None.</span>
<span class="sd">            extra_create_args (Mapping[str, Any], optional): Additional arguments for the creation process. Default to `{}`.</span>
<span class="sd">            cancellation_token (Optional[CancellationToken], optional): A token to cancel the operation. Defaults to None.</span>
<span class="sd">            max_consecutive_empty_chunk_tolerance (int): [Deprecated] The maximum number of consecutive empty chunks to tolerate before raising a ValueError. This seems to only be needed to set when using `AzureOpenAIChatCompletionClient`. Defaults to 0. This parameter is deprecated, empty chunks will be skipped.</span>

<span class="sd">        Yields:</span>
<span class="sd">            AsyncGenerator[Union[str, CreateResult], None]: A generator yielding the completion results as they are produced.</span>

<span class="sd">        In streaming, the default behaviour is not return token usage counts. See: [OpenAI API reference for possible args](https://platform.openai.com/docs/api-reference/chat/create).</span>
<span class="sd">        However `extra_create_args={&quot;stream_options&quot;: {&quot;include_usage&quot;: True}}` will (if supported by the accessed API)</span>
<span class="sd">        return a final chunk with usage set to a RequestUsage object having prompt and completion token counts,</span>
<span class="sd">        all preceding chunks will have usage as None. See: [stream_options](https://platform.openai.com/docs/api-reference/chat/create#chat-create-stream_options).</span>

<span class="sd">        Other examples of OPENAI supported arguments that can be included in `extra_create_args`:</span>
<span class="sd">            - `temperature` (float): Controls the randomness of the output. Higher values (e.g., 0.8) make the output more random, while lower values (e.g., 0.2) make it more focused and deterministic.</span>
<span class="sd">            - `max_tokens` (int): The maximum number of tokens to generate in the completion.</span>
<span class="sd">            - `top_p` (float): An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass.</span>
<span class="sd">            - `frequency_penalty` (float): A value between -2.0 and 2.0 that penalizes new tokens based on their existing frequency in the text so far, decreasing the likelihood of repeated phrases.</span>
<span class="sd">            - `presence_penalty` (float): A value between -2.0 and 2.0 that penalizes new tokens based on whether they appear in the text so far, encouraging the model to talk about new topics.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Make sure all extra_create_args are valid</span>
        <span class="n">extra_create_args_keys</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">extra_create_args</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">create_kwargs</span><span class="o">.</span><span class="n">issuperset</span><span class="p">(</span><span class="n">extra_create_args_keys</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Extra create args are invalid: </span><span class="si">{</span><span class="n">extra_create_args_keys</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">create_kwargs</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Copy the create args and overwrite anything in extra_create_args</span>
        <span class="n">create_args</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_args</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">create_args</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">extra_create_args</span><span class="p">)</span>

        <span class="c1"># Declare use_beta_client</span>
        <span class="n">use_beta_client</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">response_format_value</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Type</span><span class="p">[</span><span class="n">BaseModel</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="s2">&quot;response_format&quot;</span> <span class="ow">in</span> <span class="n">create_args</span><span class="p">:</span>
            <span class="n">value</span> <span class="o">=</span> <span class="n">create_args</span><span class="p">[</span><span class="s2">&quot;response_format&quot;</span><span class="p">]</span>
            <span class="c1"># If value is a Pydantic model class, use the beta client</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">type</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">issubclass</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">BaseModel</span><span class="p">):</span>
                <span class="n">response_format_value</span> <span class="o">=</span> <span class="n">value</span>
                <span class="n">use_beta_client</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># response_format_value is not a Pydantic model class</span>
                <span class="n">use_beta_client</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="n">response_format_value</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Remove &#39;response_format&#39; from create_args to prevent passing it twice</span>
        <span class="n">create_args_no_response_format</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">create_args</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span> <span class="o">!=</span> <span class="s2">&quot;response_format&quot;</span><span class="p">}</span>

        <span class="c1"># TODO: allow custom handling.</span>
        <span class="c1"># For now we raise an error if images are present and vision is not supported</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_info</span><span class="p">[</span><span class="s2">&quot;vision&quot;</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">message</span> <span class="ow">in</span> <span class="n">messages</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">message</span><span class="p">,</span> <span class="n">UserMessage</span><span class="p">):</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">any</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Image</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="p">):</span>
                        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Model does not support vision and image was provided&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">json_output</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_info</span><span class="p">[</span><span class="s2">&quot;json_output&quot;</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">False</span> <span class="ow">and</span> <span class="n">json_output</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Model does not support JSON output&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">json_output</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                <span class="n">create_args</span><span class="p">[</span><span class="s2">&quot;response_format&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;json_object&quot;</span><span class="p">}</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">create_args</span><span class="p">[</span><span class="s2">&quot;response_format&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;text&quot;</span><span class="p">}</span>

        <span class="n">oai_messages_nested</span> <span class="o">=</span> <span class="p">[</span><span class="n">to_oai_type</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">prepend_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_add_name_prefixes</span><span class="p">)</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">messages</span><span class="p">]</span>
        <span class="n">oai_messages</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span> <span class="k">for</span> <span class="n">sublist</span> <span class="ow">in</span> <span class="n">oai_messages_nested</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">sublist</span><span class="p">]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_info</span><span class="p">[</span><span class="s2">&quot;function_calling&quot;</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">False</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">tools</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Model does not support function calling&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">max_consecutive_empty_chunk_tolerance</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;The &#39;max_consecutive_empty_chunk_tolerance&#39; parameter is deprecated and will be removed in the future releases. All of empty chunks will be skipped with a warning.&quot;</span><span class="p">,</span>
                <span class="ne">DeprecationWarning</span><span class="p">,</span>
                <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">tool_params</span> <span class="o">=</span> <span class="n">convert_tools</span><span class="p">(</span><span class="n">tools</span><span class="p">)</span>

        <span class="c1"># Get the async generator of chunks.</span>
        <span class="k">if</span> <span class="n">use_beta_client</span><span class="p">:</span>
            <span class="n">chunks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_stream_chunks_beta_client</span><span class="p">(</span>
                <span class="n">tool_params</span><span class="o">=</span><span class="n">tool_params</span><span class="p">,</span>
                <span class="n">oai_messages</span><span class="o">=</span><span class="n">oai_messages</span><span class="p">,</span>
                <span class="n">response_format</span><span class="o">=</span><span class="n">response_format_value</span><span class="p">,</span>
                <span class="n">create_args_no_response_format</span><span class="o">=</span><span class="n">create_args_no_response_format</span><span class="p">,</span>
                <span class="n">cancellation_token</span><span class="o">=</span><span class="n">cancellation_token</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">chunks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_stream_chunks</span><span class="p">(</span>
                <span class="n">tool_params</span><span class="o">=</span><span class="n">tool_params</span><span class="p">,</span>
                <span class="n">oai_messages</span><span class="o">=</span><span class="n">oai_messages</span><span class="p">,</span>
                <span class="n">create_args</span><span class="o">=</span><span class="n">create_args</span><span class="p">,</span>
                <span class="n">cancellation_token</span><span class="o">=</span><span class="n">cancellation_token</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># Prepare data to process streaming chunks.</span>
        <span class="n">choice</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ParsedChoice</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span> <span class="n">ParsedChoice</span><span class="p">[</span><span class="n">BaseModel</span><span class="p">],</span> <span class="n">ChunkChoice</span><span class="p">]</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">ChunkChoice</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">chunk</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">stop_reason</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">maybe_model</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">content_deltas</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">full_tool_calls</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">FunctionCall</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">completion_tokens</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">logprobs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">ChatCompletionTokenLogprob</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="n">empty_chunk_warning_has_been_issued</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">empty_chunk_warning_threshold</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span>
        <span class="n">empty_chunk_count</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># Process the stream of chunks.</span>
        <span class="k">async</span> <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">chunks</span><span class="p">:</span>
            <span class="c1"># Empty chunks has been observed when the endpoint is under heavy load.</span>
            <span class="c1">#  https://github.com/FedML-AI/AgentOpera/issues/4213</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">chunk</span><span class="o">.</span><span class="n">choices</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">empty_chunk_count</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">empty_chunk_warning_has_been_issued</span> <span class="ow">and</span> <span class="n">empty_chunk_count</span> <span class="o">&gt;=</span> <span class="n">empty_chunk_warning_threshold</span><span class="p">:</span>
                    <span class="n">empty_chunk_warning_has_been_issued</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Received more than </span><span class="si">{</span><span class="n">empty_chunk_warning_threshold</span><span class="si">}</span><span class="s2"> consecutive empty chunks. Empty chunks are being ignored.&quot;</span><span class="p">,</span>
                        <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="k">continue</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">empty_chunk_count</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="c1"># to process usage chunk in streaming situations</span>
            <span class="c1"># add    stream_options={&quot;include_usage&quot;: True} in the initialization of OpenAIChatCompletionClient(...)</span>
            <span class="c1"># However the different api&#39;s</span>
            <span class="c1"># OPENAI api usage chunk produces no choices so need to check if there is a choice</span>
            <span class="c1"># liteLLM api usage chunk does produce choices</span>
            <span class="n">choice</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">chunk</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">chunk</span><span class="o">.</span><span class="n">choices</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span>
                <span class="k">else</span> <span class="n">choice</span>
                <span class="k">if</span> <span class="n">chunk</span><span class="o">.</span><span class="n">usage</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">stop_reason</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                <span class="k">else</span> <span class="n">cast</span><span class="p">(</span><span class="n">ChunkChoice</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="p">)</span>

            <span class="c1"># for liteLLM chunk usage, do the following hack keeping the pervious chunk.stop_reason (if set).</span>
            <span class="c1"># set the stop_reason for the usage chunk to the prior stop_reason</span>
            <span class="n">stop_reason</span> <span class="o">=</span> <span class="n">choice</span><span class="o">.</span><span class="n">finish_reason</span> <span class="k">if</span> <span class="n">chunk</span><span class="o">.</span><span class="n">usage</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">stop_reason</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">stop_reason</span>
            <span class="n">maybe_model</span> <span class="o">=</span> <span class="n">chunk</span><span class="o">.</span><span class="n">model</span>
            <span class="c1"># First try get content</span>
            <span class="k">if</span> <span class="n">choice</span><span class="o">.</span><span class="n">delta</span><span class="o">.</span><span class="n">content</span><span class="p">:</span>
                <span class="n">content_deltas</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">choice</span><span class="o">.</span><span class="n">delta</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">choice</span><span class="o">.</span><span class="n">delta</span><span class="o">.</span><span class="n">content</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">yield</span> <span class="n">choice</span><span class="o">.</span><span class="n">delta</span><span class="o">.</span><span class="n">content</span>
                <span class="c1"># NOTE: for OpenAI, tool_calls and content are mutually exclusive it seems, so we can skip the rest of the loop.</span>
                <span class="c1"># However, this may not be the case for other APIs -- we should expect this may need to be updated.</span>
                <span class="k">continue</span>

            <span class="c1"># Otherwise, get tool calls</span>
            <span class="k">if</span> <span class="n">choice</span><span class="o">.</span><span class="n">delta</span><span class="o">.</span><span class="n">tool_calls</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">tool_call_chunk</span> <span class="ow">in</span> <span class="n">choice</span><span class="o">.</span><span class="n">delta</span><span class="o">.</span><span class="n">tool_calls</span><span class="p">:</span>
                    <span class="n">idx</span> <span class="o">=</span> <span class="n">tool_call_chunk</span><span class="o">.</span><span class="n">index</span>
                    <span class="k">if</span> <span class="n">idx</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">full_tool_calls</span><span class="p">:</span>
                        <span class="c1"># We ignore the type hint here because we want to fill in type when the delta provides it</span>
                        <span class="n">full_tool_calls</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">FunctionCall</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">arguments</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">)</span>

                    <span class="k">if</span> <span class="n">tool_call_chunk</span><span class="o">.</span><span class="n">id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">full_tool_calls</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">id</span> <span class="o">=</span> <span class="n">clip_tool_call_id</span><span class="p">(</span><span class="n">full_tool_calls</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">id</span> <span class="o">+</span> <span class="n">tool_call_chunk</span><span class="o">.</span><span class="n">id</span><span class="p">)</span>


                    <span class="k">if</span> <span class="n">tool_call_chunk</span><span class="o">.</span><span class="n">function</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">tool_call_chunk</span><span class="o">.</span><span class="n">function</span><span class="o">.</span><span class="n">name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                            <span class="n">full_tool_calls</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">name</span> <span class="o">+=</span> <span class="n">tool_call_chunk</span><span class="o">.</span><span class="n">function</span><span class="o">.</span><span class="n">name</span>
                        <span class="k">if</span> <span class="n">tool_call_chunk</span><span class="o">.</span><span class="n">function</span><span class="o">.</span><span class="n">arguments</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                            <span class="n">full_tool_calls</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">arguments</span> <span class="o">+=</span> <span class="n">tool_call_chunk</span><span class="o">.</span><span class="n">function</span><span class="o">.</span><span class="n">arguments</span>
            <span class="k">if</span> <span class="n">choice</span><span class="o">.</span><span class="n">logprobs</span> <span class="ow">and</span> <span class="n">choice</span><span class="o">.</span><span class="n">logprobs</span><span class="o">.</span><span class="n">content</span><span class="p">:</span>
                <span class="n">logprobs</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">ChatCompletionTokenLogprob</span><span class="p">(</span>
                        <span class="n">token</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">token</span><span class="p">,</span>
                        <span class="n">logprob</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">logprob</span><span class="p">,</span>
                        <span class="n">top_logprobs</span><span class="o">=</span><span class="p">[</span><span class="n">TopLogprob</span><span class="p">(</span><span class="n">logprob</span><span class="o">=</span><span class="n">y</span><span class="o">.</span><span class="n">logprob</span><span class="p">,</span> <span class="nb">bytes</span><span class="o">=</span><span class="n">y</span><span class="o">.</span><span class="n">bytes</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">x</span><span class="o">.</span><span class="n">top_logprobs</span><span class="p">],</span>
                        <span class="nb">bytes</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">bytes</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">choice</span><span class="o">.</span><span class="n">logprobs</span><span class="o">.</span><span class="n">content</span>
                <span class="p">]</span>

        <span class="c1"># Finalize the CreateResult.</span>

        <span class="c1"># TODO: can we remove this?</span>
        <span class="k">if</span> <span class="n">stop_reason</span> <span class="o">==</span> <span class="s2">&quot;function_call&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Function calls are not supported in this context&quot;</span><span class="p">)</span>

        <span class="c1"># We need to get the model from the last chunk, if available.</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">maybe_model</span> <span class="ow">or</span> <span class="n">create_args</span><span class="p">[</span><span class="s2">&quot;model&quot;</span><span class="p">]</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;gpt-35&quot;</span><span class="p">,</span> <span class="s2">&quot;gpt-3.5&quot;</span><span class="p">)</span>  <span class="c1"># hack for Azure API</span>

        <span class="c1"># Because the usage chunk is not guaranteed to be the last chunk, we need to check if it is available.</span>
        <span class="k">if</span> <span class="n">chunk</span> <span class="ow">and</span> <span class="n">chunk</span><span class="o">.</span><span class="n">usage</span><span class="p">:</span>
            <span class="n">prompt_tokens</span> <span class="o">=</span> <span class="n">chunk</span><span class="o">.</span><span class="n">usage</span><span class="o">.</span><span class="n">prompt_tokens</span>
            <span class="n">completion_tokens</span> <span class="o">=</span> <span class="n">chunk</span><span class="o">.</span><span class="n">usage</span><span class="o">.</span><span class="n">completion_tokens</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">prompt_tokens</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">completion_tokens</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">usage</span> <span class="o">=</span> <span class="n">RequestUsage</span><span class="p">(</span>
            <span class="n">prompt_tokens</span><span class="o">=</span><span class="n">prompt_tokens</span><span class="p">,</span>
            <span class="n">completion_tokens</span><span class="o">=</span><span class="n">completion_tokens</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Detect whether it is a function call or just text.</span>
        <span class="n">content</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">FunctionCall</span><span class="p">]]</span>
        <span class="n">thought</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">full_tool_calls</span><span class="p">:</span>
            <span class="c1"># This is a tool call.</span>
            <span class="n">content</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">full_tool_calls</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">content_deltas</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="c1"># Put additional text content in the thought field.</span>
                <span class="n">thought</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">content_deltas</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">content_deltas</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># This is a text-only content.</span>
            <span class="n">content</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">content_deltas</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;No text content or tool calls are available. Model returned empty result.&quot;</span><span class="p">,</span> <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">content</span> <span class="o">=</span> <span class="s2">&quot;[WARNING]: No text content or tool calls are available. Model returned empty result.&quot;</span>

        <span class="c1"># Parse R1 content if needed.</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">content</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_info</span><span class="p">[</span><span class="s2">&quot;family&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">ModelFamily</span><span class="o">.</span><span class="n">R1</span><span class="p">:</span>
            <span class="n">thought</span><span class="p">,</span> <span class="n">content</span> <span class="o">=</span> <span class="n">parse_r1_content</span><span class="p">(</span><span class="n">content</span><span class="p">)</span>

        <span class="c1"># Create the result.</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">CreateResult</span><span class="p">(</span>
            <span class="n">finish_reason</span><span class="o">=</span><span class="n">normalize_stop_reason</span><span class="p">(</span><span class="n">stop_reason</span><span class="p">),</span>
            <span class="n">content</span><span class="o">=</span><span class="n">content</span><span class="p">,</span>
            <span class="n">usage</span><span class="o">=</span><span class="n">usage</span><span class="p">,</span>
            <span class="n">cached</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">logprobs</span><span class="o">=</span><span class="n">logprobs</span><span class="p">,</span>
            <span class="n">thought</span><span class="o">=</span><span class="n">thought</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Update the total usage.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_total_usage</span> <span class="o">=</span> <span class="n">_add_usage</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_total_usage</span><span class="p">,</span> <span class="n">usage</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_actual_usage</span> <span class="o">=</span> <span class="n">_add_usage</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_actual_usage</span><span class="p">,</span> <span class="n">usage</span><span class="p">)</span>

        <span class="c1"># Yield the CreateResult.</span>
        <span class="k">yield</span> <span class="n">result</span></div>


    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">_create_stream_chunks</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">tool_params</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">ChatCompletionToolParam</span><span class="p">],</span>
        <span class="n">oai_messages</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">ChatCompletionMessageParam</span><span class="p">],</span>
        <span class="n">create_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
        <span class="n">cancellation_token</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">CancellationToken</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">AsyncGenerator</span><span class="p">[</span><span class="n">ChatCompletionChunk</span><span class="p">,</span> <span class="kc">None</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Streams chat completion chunks with safe cancellation and cleanup.&quot;&quot;&quot;</span>
        <span class="n">stream_future</span> <span class="o">=</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">ensure_future</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
                <span class="n">messages</span><span class="o">=</span><span class="n">oai_messages</span><span class="p">,</span>
                <span class="n">stream</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">tools</span><span class="o">=</span><span class="n">tool_params</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">tool_params</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">NOT_GIVEN</span><span class="p">,</span>
                <span class="o">**</span><span class="n">create_args</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">cancellation_token</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">cancellation_token</span><span class="o">.</span><span class="n">link_future</span><span class="p">(</span><span class="n">stream_future</span><span class="p">)</span>

        <span class="n">stream</span> <span class="o">=</span> <span class="kc">None</span> 
        <span class="k">try</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">stream</span> <span class="o">=</span> <span class="k">await</span> <span class="n">stream_future</span>
            <span class="k">except</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">CancelledError</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;stream cancelled before starting&quot;</span><span class="p">)</span>
                <span class="k">return</span>
            <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">chunk_future</span> <span class="o">=</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">ensure_future</span><span class="p">(</span><span class="n">anext</span><span class="p">(</span><span class="n">stream</span><span class="p">))</span>

                    <span class="k">if</span> <span class="n">cancellation_token</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">cancellation_token</span><span class="o">.</span><span class="n">link_future</span><span class="p">(</span><span class="n">chunk_future</span><span class="p">)</span>

                    <span class="n">chunk</span> <span class="o">=</span> <span class="k">await</span> <span class="n">chunk_future</span>

                    <span class="k">if</span> <span class="n">cancellation_token</span> <span class="ow">and</span> <span class="n">cancellation_token</span><span class="o">.</span><span class="n">is_cancelled</span><span class="p">():</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Cancellation detected after receiving chunk  skipping yield.&quot;</span><span class="p">)</span>
                        <span class="k">break</span>

                    <span class="k">yield</span> <span class="n">chunk</span>

                <span class="k">except</span> <span class="ne">StopAsyncIteration</span><span class="p">:</span>
                    <span class="k">break</span>

                <span class="k">except</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">CancelledError</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;CancelledError received  aborting stream.&quot;</span><span class="p">)</span>
                    <span class="k">break</span>

                <span class="k">except</span> <span class="ne">RuntimeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Runtime error: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="k">break</span>

                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unexpected stream error: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="k">break</span>

        <span class="k">finally</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">stream</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="k">await</span> <span class="n">stream</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
                <span class="k">except</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">CancelledError</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;stream Cancelled during stream close.&quot;</span><span class="p">)</span>
                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to close stream: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>


    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">_create_stream_chunks_beta_client</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">tool_params</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">ChatCompletionToolParam</span><span class="p">],</span>
        <span class="n">oai_messages</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">ChatCompletionMessageParam</span><span class="p">],</span>
        <span class="n">create_args_no_response_format</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
        <span class="n">response_format</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Type</span><span class="p">[</span><span class="n">BaseModel</span><span class="p">]],</span>
        <span class="n">cancellation_token</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">CancellationToken</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">AsyncGenerator</span><span class="p">[</span><span class="n">ChatCompletionChunk</span><span class="p">,</span> <span class="kc">None</span><span class="p">]:</span>
        <span class="k">async</span> <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_client</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">stream</span><span class="p">(</span>
            <span class="n">messages</span><span class="o">=</span><span class="n">oai_messages</span><span class="p">,</span>
            <span class="n">tools</span><span class="o">=</span><span class="n">tool_params</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">tool_params</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">NOT_GIVEN</span><span class="p">,</span>
            <span class="n">response_format</span><span class="o">=</span><span class="n">response_format</span> <span class="k">if</span> <span class="n">response_format</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">NOT_GIVEN</span><span class="p">,</span>
            <span class="o">**</span><span class="n">create_args_no_response_format</span><span class="p">,</span>
        <span class="p">)</span> <span class="k">as</span> <span class="n">stream</span><span class="p">:</span>
            <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">event_future</span> <span class="o">=</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">ensure_future</span><span class="p">(</span><span class="n">anext</span><span class="p">(</span><span class="n">stream</span><span class="p">))</span>
                    <span class="k">if</span> <span class="n">cancellation_token</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">cancellation_token</span><span class="o">.</span><span class="n">link_future</span><span class="p">(</span><span class="n">event_future</span><span class="p">)</span>
                    <span class="n">event</span> <span class="o">=</span> <span class="k">await</span> <span class="n">event_future</span>

                    <span class="k">if</span> <span class="n">event</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s2">&quot;chunk&quot;</span><span class="p">:</span>
                        <span class="n">chunk</span> <span class="o">=</span> <span class="n">event</span><span class="o">.</span><span class="n">chunk</span>
                        <span class="k">yield</span> <span class="n">chunk</span>
                    <span class="c1"># We don&#39;t handle other event types from the beta client stream.</span>
                    <span class="c1"># As the other event types are auxiliary to the chunk event.</span>
                    <span class="c1"># See: https://github.com/openai/openai-python/blob/main/helpers.md#chat-completions-events.</span>
                    <span class="c1"># Once the beta client is stable, we can move all the logic to the beta client.</span>
                    <span class="c1"># Then we can consider handling other event types which may simplify the code overall.</span>
                <span class="k">except</span> <span class="ne">StopAsyncIteration</span><span class="p">:</span>
                    <span class="k">break</span>

<div class="viewcode-block" id="BaseOpenAIChatCompletionClient.actual_usage">
<a class="viewcode-back" href="../../../../models/models.openai.html#agentopera.models.openai.BaseOpenAIChatCompletionClient.actual_usage">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">actual_usage</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RequestUsage</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_actual_usage</span></div>


<div class="viewcode-block" id="BaseOpenAIChatCompletionClient.total_usage">
<a class="viewcode-back" href="../../../../models/models.openai.html#agentopera.models.openai.BaseOpenAIChatCompletionClient.total_usage">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">total_usage</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RequestUsage</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_total_usage</span></div>


<div class="viewcode-block" id="BaseOpenAIChatCompletionClient.count_tokens">
<a class="viewcode-back" href="../../../../models/models.openai.html#agentopera.models.openai.BaseOpenAIChatCompletionClient.count_tokens">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">count_tokens</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">messages</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">LLMMessage</span><span class="p">],</span> <span class="o">*</span><span class="p">,</span> <span class="n">tools</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Tool</span> <span class="o">|</span> <span class="n">ToolSchema</span><span class="p">]</span> <span class="o">=</span> <span class="p">[])</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_args</span><span class="p">[</span><span class="s2">&quot;model&quot;</span><span class="p">]</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">encoding</span> <span class="o">=</span> <span class="n">tiktoken</span><span class="o">.</span><span class="n">encoding_for_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
            <span class="n">trace_logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model </span><span class="si">{</span><span class="n">model</span><span class="si">}</span><span class="s2"> not found. Using cl100k_base encoding.&quot;</span><span class="p">)</span>
            <span class="n">encoding</span> <span class="o">=</span> <span class="n">tiktoken</span><span class="o">.</span><span class="n">get_encoding</span><span class="p">(</span><span class="s2">&quot;cl100k_base&quot;</span><span class="p">)</span>
        <span class="n">tokens_per_message</span> <span class="o">=</span> <span class="mi">3</span>
        <span class="n">tokens_per_name</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">num_tokens</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># Message tokens.</span>
        <span class="k">for</span> <span class="n">message</span> <span class="ow">in</span> <span class="n">messages</span><span class="p">:</span>
            <span class="n">num_tokens</span> <span class="o">+=</span> <span class="n">tokens_per_message</span>
            <span class="n">oai_message</span> <span class="o">=</span> <span class="n">to_oai_type</span><span class="p">(</span><span class="n">message</span><span class="p">,</span> <span class="n">prepend_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_add_name_prefixes</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">oai_message_part</span> <span class="ow">in</span> <span class="n">oai_message</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">oai_message_part</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="k">if</span> <span class="n">value</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="k">continue</span>

                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">message</span><span class="p">,</span> <span class="n">UserMessage</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                        <span class="n">typed_message_value</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">List</span><span class="p">[</span><span class="n">ChatCompletionContentPartParam</span><span class="p">],</span> <span class="n">value</span><span class="p">)</span>

                        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">typed_message_value</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span>
                            <span class="n">message</span><span class="o">.</span><span class="n">content</span>
                        <span class="p">),</span> <span class="s2">&quot;Mismatch in message content and typed message value&quot;</span>

                        <span class="c1"># We need image properties that are only in the original message</span>
                        <span class="k">for</span> <span class="n">part</span><span class="p">,</span> <span class="n">content_part</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">typed_message_value</span><span class="p">,</span> <span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
                            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">content_part</span><span class="p">,</span> <span class="n">Image</span><span class="p">):</span>
                                <span class="c1"># TODO: add detail parameter</span>
                                <span class="n">num_tokens</span> <span class="o">+=</span> <span class="n">calculate_vision_tokens</span><span class="p">(</span><span class="n">content_part</span><span class="p">)</span>
                            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">part</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                                <span class="n">num_tokens</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">encoding</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">part</span><span class="p">))</span>
                            <span class="k">else</span><span class="p">:</span>
                                <span class="k">try</span><span class="p">:</span>
                                    <span class="n">serialized_part</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">part</span><span class="p">)</span>
                                    <span class="n">num_tokens</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">encoding</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">serialized_part</span><span class="p">))</span>
                                <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
                                    <span class="n">trace_logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Could not convert </span><span class="si">{</span><span class="n">part</span><span class="si">}</span><span class="s2"> to string, skipping.&quot;</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                            <span class="k">try</span><span class="p">:</span>
                                <span class="n">value</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
                            <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
                                <span class="n">trace_logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Could not convert </span><span class="si">{</span><span class="n">value</span><span class="si">}</span><span class="s2"> to string, skipping.&quot;</span><span class="p">)</span>
                                <span class="k">continue</span>
                        <span class="n">num_tokens</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">encoding</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">value</span><span class="p">))</span>
                        <span class="k">if</span> <span class="n">key</span> <span class="o">==</span> <span class="s2">&quot;name&quot;</span><span class="p">:</span>
                            <span class="n">num_tokens</span> <span class="o">+=</span> <span class="n">tokens_per_name</span>
        <span class="n">num_tokens</span> <span class="o">+=</span> <span class="mi">3</span>  <span class="c1"># every reply is primed with &lt;|start|&gt;assistant&lt;|message|&gt;</span>

        <span class="c1"># Tool tokens.</span>
        <span class="n">oai_tools</span> <span class="o">=</span> <span class="n">convert_tools</span><span class="p">(</span><span class="n">tools</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">tool</span> <span class="ow">in</span> <span class="n">oai_tools</span><span class="p">:</span>
            <span class="n">function</span> <span class="o">=</span> <span class="n">tool</span><span class="p">[</span><span class="s2">&quot;function&quot;</span><span class="p">]</span>
            <span class="n">tool_tokens</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">encoding</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">function</span><span class="p">[</span><span class="s2">&quot;name&quot;</span><span class="p">]))</span>
            <span class="k">if</span> <span class="s2">&quot;description&quot;</span> <span class="ow">in</span> <span class="n">function</span><span class="p">:</span>
                <span class="n">tool_tokens</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">encoding</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">function</span><span class="p">[</span><span class="s2">&quot;description&quot;</span><span class="p">]))</span>
            <span class="n">tool_tokens</span> <span class="o">-=</span> <span class="mi">2</span>
            <span class="k">if</span> <span class="s2">&quot;parameters&quot;</span> <span class="ow">in</span> <span class="n">function</span><span class="p">:</span>
                <span class="n">parameters</span> <span class="o">=</span> <span class="n">function</span><span class="p">[</span><span class="s2">&quot;parameters&quot;</span><span class="p">]</span>
                <span class="k">if</span> <span class="s2">&quot;properties&quot;</span> <span class="ow">in</span> <span class="n">parameters</span><span class="p">:</span>
                    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;properties&quot;</span><span class="p">],</span> <span class="nb">dict</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">propertiesKey</span> <span class="ow">in</span> <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;properties&quot;</span><span class="p">]:</span>  <span class="c1"># pyright: ignore</span>
                        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">propertiesKey</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
                        <span class="n">tool_tokens</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">encoding</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">propertiesKey</span><span class="p">))</span>
                        <span class="n">v</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;properties&quot;</span><span class="p">][</span><span class="n">propertiesKey</span><span class="p">]</span>  <span class="c1"># pyright: ignore</span>
                        <span class="k">for</span> <span class="n">field</span> <span class="ow">in</span> <span class="n">v</span><span class="p">:</span>  <span class="c1"># pyright: ignore</span>
                            <span class="k">if</span> <span class="n">field</span> <span class="o">==</span> <span class="s2">&quot;type&quot;</span><span class="p">:</span>
                                <span class="n">tool_tokens</span> <span class="o">+=</span> <span class="mi">2</span>
                                <span class="n">tool_tokens</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">encoding</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">v</span><span class="p">[</span><span class="s2">&quot;type&quot;</span><span class="p">]))</span>  <span class="c1"># pyright: ignore</span>
                            <span class="k">elif</span> <span class="n">field</span> <span class="o">==</span> <span class="s2">&quot;description&quot;</span><span class="p">:</span>
                                <span class="n">tool_tokens</span> <span class="o">+=</span> <span class="mi">2</span>
                                <span class="n">tool_tokens</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">encoding</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">v</span><span class="p">[</span><span class="s2">&quot;description&quot;</span><span class="p">]))</span>  <span class="c1"># pyright: ignore</span>
                            <span class="k">elif</span> <span class="n">field</span> <span class="o">==</span> <span class="s2">&quot;enum&quot;</span><span class="p">:</span>
                                <span class="n">tool_tokens</span> <span class="o">-=</span> <span class="mi">3</span>
                                <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">v</span><span class="p">[</span><span class="s2">&quot;enum&quot;</span><span class="p">]:</span>  <span class="c1"># pyright: ignore</span>
                                    <span class="n">tool_tokens</span> <span class="o">+=</span> <span class="mi">3</span>
                                    <span class="n">tool_tokens</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">encoding</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">o</span><span class="p">))</span>  <span class="c1"># pyright: ignore</span>
                            <span class="k">else</span><span class="p">:</span>
                                <span class="n">trace_logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Not supported field </span><span class="si">{</span><span class="n">field</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="n">tool_tokens</span> <span class="o">+=</span> <span class="mi">11</span>
                    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;properties&quot;</span><span class="p">])</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># pyright: ignore</span>
                        <span class="n">tool_tokens</span> <span class="o">-=</span> <span class="mi">2</span>
            <span class="n">num_tokens</span> <span class="o">+=</span> <span class="n">tool_tokens</span>
        <span class="n">num_tokens</span> <span class="o">+=</span> <span class="mi">12</span>
        <span class="k">return</span> <span class="n">num_tokens</span></div>


<div class="viewcode-block" id="BaseOpenAIChatCompletionClient.remaining_tokens">
<a class="viewcode-back" href="../../../../models/models.openai.html#agentopera.models.openai.BaseOpenAIChatCompletionClient.remaining_tokens">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">remaining_tokens</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">messages</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">LLMMessage</span><span class="p">],</span> <span class="o">*</span><span class="p">,</span> <span class="n">tools</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Tool</span> <span class="o">|</span> <span class="n">ToolSchema</span><span class="p">]</span> <span class="o">=</span> <span class="p">[])</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="n">token_limit</span> <span class="o">=</span> <span class="n">model_info_util</span><span class="o">.</span><span class="n">get_token_limit</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_create_args</span><span class="p">[</span><span class="s2">&quot;model&quot;</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">token_limit</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">count_tokens</span><span class="p">(</span><span class="n">messages</span><span class="p">,</span> <span class="n">tools</span><span class="o">=</span><span class="n">tools</span><span class="p">)</span></div>


    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">capabilities</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ModelCapabilities</span><span class="p">:</span>  <span class="c1"># type: ignore</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;capabilities is deprecated, use model_info instead&quot;</span><span class="p">,</span> <span class="ne">DeprecationWarning</span><span class="p">,</span> <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_info</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">model_info</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ModelInfo</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_info</span></div>



<div class="viewcode-block" id="OpenAIChatCompletionClient">
<a class="viewcode-back" href="../../../../models/models.openai.html#agentopera.models.openai.OpenAIChatCompletionClient">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">OpenAIChatCompletionClient</span><span class="p">(</span><span class="n">BaseOpenAIChatCompletionClient</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Chat completion client for OpenAI hosted models.</span>

<span class="sd">    To use this client, you must install the `openai` extra:</span>

<span class="sd">    .. code-block:: bash</span>

<span class="sd">        pip install &quot;agentopera[openai]&quot;</span>

<span class="sd">    You can also use this client for OpenAI-compatible ChatCompletion endpoints.</span>
<span class="sd">    **Using this client for non-OpenAI models is not tested or guaranteed.**</span>


<span class="sd">    Args:</span>
<span class="sd">        model (str): Which OpenAI model to use.</span>
<span class="sd">        api_key (optional, str): The API key to use. **Required if &#39;OPENAI_API_KEY&#39; is not found in the environment variables.**</span>
<span class="sd">        organization (optional, str): The organization ID to use.</span>
<span class="sd">        base_url (optional, str): The base URL to use. **Required if the model is not hosted on OpenAI.**</span>
<span class="sd">        timeout: (optional, float): The timeout for the request in seconds.</span>
<span class="sd">        max_retries (optional, int): The maximum number of retries to attempt.</span>
<span class="sd">        model_info (optional, ModelInfo): The capabilities of the model. **Required if the model name is not a valid OpenAI model.**</span>
<span class="sd">        frequency_penalty (optional, float):</span>
<span class="sd">        logit_bias: (optional, dict[str, int]):</span>
<span class="sd">        max_tokens (optional, int):</span>
<span class="sd">        n (optional, int):</span>
<span class="sd">        presence_penalty (optional, float):</span>
<span class="sd">        response_format (optional, literal[&quot;json_object&quot;, &quot;text&quot;] | pydantic.BaseModel):</span>
<span class="sd">        seed (optional, int):</span>
<span class="sd">        stop (optional, str | List[str]):</span>
<span class="sd">        temperature (optional, float):</span>
<span class="sd">        top_p (optional, float):</span>
<span class="sd">        user (optional, str):</span>
<span class="sd">        default_headers (optional, dict[str, str]):  Custom headers; useful for authentication or other custom requirements.</span>
<span class="sd">        add_name_prefixes (optional, bool): Whether to prepend the `source` value</span>
<span class="sd">            to each :class:`~agentopera.core.models.UserMessage` content. E.g.,</span>
<span class="sd">            &quot;this is content&quot; becomes &quot;Reviewer said: this is content.&quot;</span>
<span class="sd">            This can be useful for models that do not support the `name` field in</span>
<span class="sd">            message. Defaults to False.</span>
<span class="sd">        stream_options (optional, dict): Additional options for streaming. Currently only `include_usage` is supported.</span>

<span class="sd">    Examples:</span>

<span class="sd">        The following code snippet shows how to use the client with an OpenAI model:</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            from agentopera.models.openai import OpenAIChatCompletionClient</span>
<span class="sd">            from agentopera.core.types.models import UserMessage</span>

<span class="sd">            openai_client = OpenAIChatCompletionClient(</span>
<span class="sd">                model=&quot;gpt-4o-2024-08-06&quot;,</span>
<span class="sd">                # api_key=&quot;sk-...&quot;, # Optional if you have an OPENAI_API_KEY environment variable set.</span>
<span class="sd">            )</span>

<span class="sd">            result = await openai_client.create([UserMessage(content=&quot;What is the capital of France?&quot;, source=&quot;user&quot;)])  # type: ignore</span>
<span class="sd">            print(result)</span>


<span class="sd">        To use the client with a non-OpenAI model, you need to provide the base URL of the model and the model info.</span>
<span class="sd">        For example, to use Ollama, you can use the following code snippet:</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            from agentopera.models.openai import OpenAIChatCompletionClient</span>
<span class="sd">            from agentopera.core.types.models import ModelFamily</span>

<span class="sd">            custom_model_client = OpenAIChatCompletionClient(</span>
<span class="sd">                model=&quot;deepseek-r1:1.5b&quot;,</span>
<span class="sd">                base_url=&quot;http://localhost:11434/v1&quot;,</span>
<span class="sd">                api_key=&quot;placeholder&quot;,</span>
<span class="sd">                model_info={</span>
<span class="sd">                    &quot;vision&quot;: False,</span>
<span class="sd">                    &quot;function_calling&quot;: False,</span>
<span class="sd">                    &quot;json_output&quot;: False,</span>
<span class="sd">                    &quot;family&quot;: ModelFamily.R1,</span>
<span class="sd">                },</span>
<span class="sd">            )</span>

<span class="sd">        To use structured output as well as function calling, you can use the following code snippet:</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            import asyncio</span>
<span class="sd">            from typing import Literal</span>

<span class="sd">            from agentopera.core.types.models import (</span>
<span class="sd">                AssistantMessage,</span>
<span class="sd">                FunctionExecutionResult,</span>
<span class="sd">                FunctionExecutionResultMessage,</span>
<span class="sd">                SystemMessage,</span>
<span class="sd">                UserMessage,</span>
<span class="sd">            )</span>
<span class="sd">            from agentopera.core.tools import FunctionTool</span>
<span class="sd">            from agentopera.models.openai import OpenAIChatCompletionClient</span>
<span class="sd">            from pydantic import BaseModel</span>


<span class="sd">            # Define the structured output format.</span>
<span class="sd">            class AgentResponse(BaseModel):</span>
<span class="sd">                thoughts: str</span>
<span class="sd">                response: Literal[&quot;happy&quot;, &quot;sad&quot;, &quot;neutral&quot;]</span>


<span class="sd">            # Define the function to be called as a tool.</span>
<span class="sd">            def sentiment_analysis(text: str) -&gt; str:</span>
<span class="sd">                \&quot;\&quot;\&quot;Given a text, return the sentiment.\&quot;\&quot;\&quot;</span>
<span class="sd">                return &quot;happy&quot; if &quot;happy&quot; in text else &quot;sad&quot; if &quot;sad&quot; in text else &quot;neutral&quot;</span>


<span class="sd">            # Create a FunctionTool instance with `strict=True`,</span>
<span class="sd">            # which is required for structured output mode.</span>
<span class="sd">            tool = FunctionTool(sentiment_analysis, description=&quot;Sentiment Analysis&quot;, strict=True)</span>

<span class="sd">            # Create an OpenAIChatCompletionClient instance.</span>
<span class="sd">            model_client = OpenAIChatCompletionClient(</span>
<span class="sd">                model=&quot;gpt-4o-mini&quot;,</span>
<span class="sd">                response_format=AgentResponse,  # type: ignore</span>
<span class="sd">            )</span>


<span class="sd">            async def main() -&gt; None:</span>
<span class="sd">                # Generate a response using the tool.</span>
<span class="sd">                response1 = await model_client.create(</span>
<span class="sd">                    messages=[</span>
<span class="sd">                        SystemMessage(content=&quot;Analyze input text sentiment using the tool provided.&quot;),</span>
<span class="sd">                        UserMessage(content=&quot;I am happy.&quot;, source=&quot;user&quot;),</span>
<span class="sd">                    ],</span>
<span class="sd">                    tools=[tool],</span>
<span class="sd">                )</span>
<span class="sd">                print(response1.content)</span>
<span class="sd">                # Should be a list of tool calls.</span>
<span class="sd">                # [FunctionCall(name=&quot;sentiment_analysis&quot;, arguments={&quot;text&quot;: &quot;I am happy.&quot;}, ...)]</span>

<span class="sd">                assert isinstance(response1.content, list)</span>
<span class="sd">                response2 = await model_client.create(</span>
<span class="sd">                    messages=[</span>
<span class="sd">                        SystemMessage(content=&quot;Analyze input text sentiment using the tool provided.&quot;),</span>
<span class="sd">                        UserMessage(content=&quot;I am happy.&quot;, source=&quot;user&quot;),</span>
<span class="sd">                        AssistantMessage(content=response1.content, source=&quot;assistant&quot;),</span>
<span class="sd">                        FunctionExecutionResultMessage(</span>
<span class="sd">                            content=[FunctionExecutionResult(content=&quot;happy&quot;, call_id=response1.content[0].id, is_error=False, name=&quot;sentiment_analysis&quot;)]</span>
<span class="sd">                        ),</span>
<span class="sd">                    ],</span>
<span class="sd">                )</span>
<span class="sd">                print(response2.content)</span>
<span class="sd">                # Should be a structured output.</span>
<span class="sd">                # {&quot;thoughts&quot;: &quot;The user is happy.&quot;, &quot;response&quot;: &quot;happy&quot;}</span>


<span class="sd">            asyncio.run(main())</span>


<span class="sd">        To load the client from a configuration, you can use the `load_component` method:</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            from agentopera.core.types.models import ChatCompletionClient</span>

<span class="sd">            config = {</span>
<span class="sd">                &quot;provider&quot;: &quot;OpenAIChatCompletionClient&quot;,</span>
<span class="sd">                &quot;config&quot;: {&quot;model&quot;: &quot;gpt-4o&quot;, &quot;api_key&quot;: &quot;REPLACE_WITH_YOUR_API_KEY&quot;},</span>
<span class="sd">            }</span>

<span class="sd">            client = ChatCompletionClient.load_component(config)</span>

<span class="sd">        To view the full list of available configuration options, see the :py:class:`OpenAIClientConfigurationConfigModel` class.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Unpack</span><span class="p">[</span><span class="n">OpenAIClientConfiguration</span><span class="p">]):</span>
        <span class="k">if</span> <span class="s2">&quot;model&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;model is required for OpenAIChatCompletionClient&quot;</span><span class="p">)</span>

        <span class="n">model_capabilities</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ModelCapabilities</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># type: ignore</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_raw_config</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">copied_args</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

        <span class="k">if</span> <span class="s2">&quot;model_capabilities&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">model_capabilities</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;model_capabilities&quot;</span><span class="p">]</span>
            <span class="k">del</span> <span class="n">copied_args</span><span class="p">[</span><span class="s2">&quot;model_capabilities&quot;</span><span class="p">]</span>

        <span class="n">model_info</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ModelInfo</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="s2">&quot;model_info&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">model_info</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;model_info&quot;</span><span class="p">]</span>
            <span class="k">del</span> <span class="n">copied_args</span><span class="p">[</span><span class="s2">&quot;model_info&quot;</span><span class="p">]</span>

        <span class="n">add_name_prefixes</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="s2">&quot;add_name_prefixes&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">add_name_prefixes</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;add_name_prefixes&quot;</span><span class="p">]</span>

        <span class="c1"># Special handling for Gemini model.</span>
        <span class="k">assert</span> <span class="s2">&quot;model&quot;</span> <span class="ow">in</span> <span class="n">copied_args</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">copied_args</span><span class="p">[</span><span class="s2">&quot;model&quot;</span><span class="p">],</span> <span class="nb">str</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">copied_args</span><span class="p">[</span><span class="s2">&quot;model&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;gemini-&quot;</span><span class="p">):</span>
            <span class="k">if</span> <span class="s2">&quot;base_url&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">copied_args</span><span class="p">:</span>
                <span class="n">copied_args</span><span class="p">[</span><span class="s2">&quot;base_url&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">model_info</span><span class="o">.</span><span class="n">GEMINI_OPENAI_BASE_URL</span>
            <span class="k">if</span> <span class="s2">&quot;api_key&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">copied_args</span> <span class="ow">and</span> <span class="s2">&quot;GEMINI_API_KEY&quot;</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">:</span>
                <span class="n">copied_args</span><span class="p">[</span><span class="s2">&quot;api_key&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;GEMINI_API_KEY&quot;</span><span class="p">]</span>

        <span class="n">client</span> <span class="o">=</span> <span class="n">_openai_client_from_config</span><span class="p">(</span><span class="n">copied_args</span><span class="p">)</span>
        <span class="n">create_args</span> <span class="o">=</span> <span class="n">_create_args_from_config</span><span class="p">(</span><span class="n">copied_args</span><span class="p">)</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">client</span><span class="o">=</span><span class="n">client</span><span class="p">,</span>
            <span class="n">create_args</span><span class="o">=</span><span class="n">create_args</span><span class="p">,</span>
            <span class="n">model_capabilities</span><span class="o">=</span><span class="n">model_capabilities</span><span class="p">,</span>
            <span class="n">model_info</span><span class="o">=</span><span class="n">model_info</span><span class="p">,</span>
            <span class="n">add_name_prefixes</span><span class="o">=</span><span class="n">add_name_prefixes</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">__getstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">state</span><span class="p">[</span><span class="s2">&quot;_client&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="n">state</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">__setstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_client</span> <span class="o">=</span> <span class="n">_openai_client_from_config</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="s2">&quot;_raw_config&quot;</span><span class="p">])</span></div>



<div class="viewcode-block" id="AzureOpenAIChatCompletionClient">
<a class="viewcode-back" href="../../../../models/models.openai.html#agentopera.models.openai.AzureOpenAIChatCompletionClient">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">AzureOpenAIChatCompletionClient</span><span class="p">(</span>
    <span class="n">BaseOpenAIChatCompletionClient</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Chat completion client for Azure OpenAI hosted models.</span>

<span class="sd">    Args:</span>

<span class="sd">        model (str): Which OpenAI model to use.</span>
<span class="sd">        azure_endpoint (str): The endpoint for the Azure model. **Required for Azure models.**</span>
<span class="sd">        azure_deployment (str): Deployment name for the Azure model. **Required for Azure models.**</span>
<span class="sd">        api_version (str): The API version to use. **Required for Azure models.**</span>
<span class="sd">        azure_ad_token (str): The Azure AD token to use. Provide this or `azure_ad_token_provider` for token-based authentication.</span>
<span class="sd">        azure_ad_token_provider (optional, Callable[[], Awaitable[str]] | AzureTokenProvider): The Azure AD token provider to use. Provide this or `azure_ad_token` for token-based authentication.</span>
<span class="sd">        api_key (optional, str): The API key to use, use this if you are using key based authentication. It is optional if you are using Azure AD token based authentication or `AZURE_OPENAI_API_KEY` environment variable.</span>
<span class="sd">        timeout: (optional, float): The timeout for the request in seconds.</span>
<span class="sd">        max_retries (optional, int): The maximum number of retries to attempt.</span>
<span class="sd">        model_info (optional, ModelInfo): The capabilities of the model. **Required if the model name is not a valid OpenAI model.**</span>
<span class="sd">        frequency_penalty (optional, float):</span>
<span class="sd">        logit_bias: (optional, dict[str, int]):</span>
<span class="sd">        max_tokens (optional, int):</span>
<span class="sd">        n (optional, int):</span>
<span class="sd">        presence_penalty (optional, float):</span>
<span class="sd">        response_format (optional, literal[&quot;json_object&quot;, &quot;text&quot;]):</span>
<span class="sd">        seed (optional, int):</span>
<span class="sd">        stop (optional, str | List[str]):</span>
<span class="sd">        temperature (optional, float):</span>
<span class="sd">        top_p (optional, float):</span>
<span class="sd">        user (optional, str):</span>
<span class="sd">        default_headers (optional, dict[str, str]):  Custom headers; useful for authentication or other custom requirements.</span>



<span class="sd">    To use this client, you must install the `azure` and `openai` extensions:</span>

<span class="sd">        .. code-block:: bash</span>

<span class="sd">            pip install &quot;agentopera[openai,azure]&quot;</span>

<span class="sd">    To use the client, you need to provide your deployment id, Azure Cognitive Services endpoint,</span>
<span class="sd">    api version, and model capabilities.</span>
<span class="sd">    For authentication, you can either provide an API key or an Azure Active Directory (AAD) token credential.</span>

<span class="sd">    The following code snippet shows how to use AAD authentication.</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            from agentopera.models.openai import AzureOpenAIChatCompletionClient</span>
<span class="sd">            from azure.identity import DefaultAzureCredential, get_bearer_token_provider</span>

<span class="sd">            # Create the token provider</span>
<span class="sd">            token_provider = get_bearer_token_provider(DefaultAzureCredential(), &quot;https://cognitiveservices.azure.com/.default&quot;)</span>

<span class="sd">            az_model_client = AzureOpenAIChatCompletionClient(</span>
<span class="sd">                azure_deployment=&quot;{your-azure-deployment}&quot;,</span>
<span class="sd">                model=&quot;{deployed-model, such as &#39;gpt-4o&#39;}&quot;,</span>
<span class="sd">                api_version=&quot;2024-06-01&quot;,</span>
<span class="sd">                azure_endpoint=&quot;https://{your-custom-endpoint}.openai.azure.com/&quot;,</span>
<span class="sd">                azure_ad_token_provider=token_provider,  # Optional if you choose key-based authentication.</span>
<span class="sd">                # api_key=&quot;sk-...&quot;, # For key-based authentication. `AZURE_OPENAI_API_KEY` environment variable can also be used instead.</span>
<span class="sd">            )</span>

<span class="sd">    To load the client that uses identity based aith from a configuration, you can use the `load_component` method:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        from agentopera.core.types.models import ChatCompletionClient</span>

<span class="sd">        config = {</span>
<span class="sd">            &quot;provider&quot;: &quot;AzureOpenAIChatCompletionClient&quot;,</span>
<span class="sd">            &quot;config&quot;: {</span>
<span class="sd">                &quot;model&quot;: &quot;gpt-4o-2024-05-13&quot;,</span>
<span class="sd">                &quot;azure_endpoint&quot;: &quot;https://{your-custom-endpoint}.openai.azure.com/&quot;,</span>
<span class="sd">                &quot;azure_deployment&quot;: &quot;{your-azure-deployment}&quot;,</span>
<span class="sd">                &quot;api_version&quot;: &quot;2024-06-01&quot;,</span>
<span class="sd">                &quot;azure_ad_token_provider&quot;: {</span>
<span class="sd">                    &quot;provider&quot;: &quot;agentopera.agents.auth.azure.AzureTokenProvider&quot;,</span>
<span class="sd">                    &quot;config&quot;: {</span>
<span class="sd">                        &quot;provider_kind&quot;: &quot;DefaultAzureCredential&quot;,</span>
<span class="sd">                        &quot;scopes&quot;: [&quot;https://cognitiveservices.azure.com/.default&quot;],</span>
<span class="sd">                    },</span>
<span class="sd">                },</span>
<span class="sd">            },</span>
<span class="sd">        }</span>

<span class="sd">        client = ChatCompletionClient.load_component(config)</span>


<span class="sd">    To view the full list of available configuration options, see the :py:class:`AzureOpenAIClientConfigurationConfigModel` class.</span>


<span class="sd">    .. note::</span>

<span class="sd">        Right now only `DefaultAzureCredential` is supported with no additional args passed to it.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Unpack</span><span class="p">[</span><span class="n">AzureOpenAIClientConfiguration</span><span class="p">]):</span>
        <span class="n">model_capabilities</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ModelCapabilities</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># type: ignore</span>
        <span class="n">copied_args</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">if</span> <span class="s2">&quot;model_capabilities&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">model_capabilities</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;model_capabilities&quot;</span><span class="p">]</span>
            <span class="k">del</span> <span class="n">copied_args</span><span class="p">[</span><span class="s2">&quot;model_capabilities&quot;</span><span class="p">]</span>

        <span class="n">model_info</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ModelInfo</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="s2">&quot;model_info&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">model_info</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;model_info&quot;</span><span class="p">]</span>
            <span class="k">del</span> <span class="n">copied_args</span><span class="p">[</span><span class="s2">&quot;model_info&quot;</span><span class="p">]</span>

        <span class="n">add_name_prefixes</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="s2">&quot;add_name_prefixes&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">add_name_prefixes</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;add_name_prefixes&quot;</span><span class="p">]</span>

        <span class="n">client</span> <span class="o">=</span> <span class="n">_azure_openai_client_from_config</span><span class="p">(</span><span class="n">copied_args</span><span class="p">)</span>
        <span class="n">create_args</span> <span class="o">=</span> <span class="n">_create_args_from_config</span><span class="p">(</span><span class="n">copied_args</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_raw_config</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="n">copied_args</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">client</span><span class="o">=</span><span class="n">client</span><span class="p">,</span>
            <span class="n">create_args</span><span class="o">=</span><span class="n">create_args</span><span class="p">,</span>
            <span class="n">model_capabilities</span><span class="o">=</span><span class="n">model_capabilities</span><span class="p">,</span>
            <span class="n">model_info</span><span class="o">=</span><span class="n">model_info</span><span class="p">,</span>
            <span class="n">add_name_prefixes</span><span class="o">=</span><span class="n">add_name_prefixes</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">__getstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">state</span><span class="p">[</span><span class="s2">&quot;_client&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="n">state</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">__setstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_client</span> <span class="o">=</span> <span class="n">_azure_openai_client_from_config</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="s2">&quot;_raw_config&quot;</span><span class="p">])</span></div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, tensoropera.ai.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>